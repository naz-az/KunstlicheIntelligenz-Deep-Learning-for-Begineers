{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EBRkh6g6Z8Yg"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the insurance dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Life-Expectancy-Data-Updated.csv\")\n",
        "\n",
        "jaz=df[df[\"Country\"]==\"Malaysia\"]\n",
        "jaz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "gzLFGocabA6G",
        "outputId": "41cfabe4-3c75-4c9d-92c6-1051ebe580df"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Country Region  Year  Infant_deaths  Under_five_deaths  \\\n",
              "107   Malaysia   Asia  2006            7.0                8.1   \n",
              "153   Malaysia   Asia  2013            6.8                8.0   \n",
              "159   Malaysia   Asia  2005            7.0                8.2   \n",
              "435   Malaysia   Asia  2003            7.3                8.5   \n",
              "513   Malaysia   Asia  2002            7.6                8.9   \n",
              "925   Malaysia   Asia  2010            6.9                8.1   \n",
              "1281  Malaysia   Asia  2011            6.8                8.0   \n",
              "1289  Malaysia   Asia  2004            7.1                8.3   \n",
              "1290  Malaysia   Asia  2001            8.1                9.4   \n",
              "1596  Malaysia   Asia  2008            6.9                8.1   \n",
              "1659  Malaysia   Asia  2009            6.9                8.1   \n",
              "1834  Malaysia   Asia  2007            6.9                8.1   \n",
              "1913  Malaysia   Asia  2014            6.8                8.0   \n",
              "2553  Malaysia   Asia  2012            6.8                8.0   \n",
              "2572  Malaysia   Asia  2000            8.7               10.2   \n",
              "2727  Malaysia   Asia  2015            6.9                8.1   \n",
              "\n",
              "      Adult_mortality  Alcohol_consumption  Hepatitis_B  Measles   BMI  ...  \\\n",
              "107          129.3760                 0.45           95       90  24.6  ...   \n",
              "153          124.6680                 0.55           96       99  25.4  ...   \n",
              "159          129.6545                 0.49           96       91  24.5  ...   \n",
              "435          130.2105                 0.51           95       91  24.2  ...   \n",
              "513          130.4885                 0.52           95       91  24.1  ...   \n",
              "925          127.3235                 0.52           96       95  25.0  ...   \n",
              "1281         126.7315                 0.54           96       95  25.1  ...   \n",
              "1289         129.9325                 0.51           94       91  24.3  ...   \n",
              "1290         132.8190                 0.52           95       91  24.0  ...   \n",
              "1596         128.5065                 0.50           97       93  24.8  ...   \n",
              "1659         127.9145                 0.50           96       95  24.9  ...   \n",
              "1834         129.0980                 0.46           96       92  24.7  ...   \n",
              "1913         123.1955                 0.54           96       99  25.5  ...   \n",
              "2553         126.1405                 0.55           97       99  25.3  ...   \n",
              "2572         135.1495                 0.56           97       91  23.8  ...   \n",
              "2727         121.7230                 0.55           99       99  25.6  ...   \n",
              "\n",
              "      Diphtheria  Incidents_HIV  GDP_per_capita  Population_mln  \\\n",
              "107           95           0.20            7531           26.20   \n",
              "153           97           0.15            9179           29.47   \n",
              "159           96           0.21            7275           25.69   \n",
              "435           96           0.24            6728           24.70   \n",
              "513           94           0.25            6488           24.21   \n",
              "925           96           0.17            8248           28.21   \n",
              "1281          96           0.16            8550           28.65   \n",
              "1289          95           0.22            7044           25.19   \n",
              "1290          96           0.27            6286           23.71   \n",
              "1596          97           0.18            8074           27.24   \n",
              "1659          97           0.18            7809           27.74   \n",
              "1834          97           0.19            7850           26.72   \n",
              "1913          97           0.15            9601           29.87   \n",
              "2553          97           0.16            8889           29.07   \n",
              "2572          98           0.26            6393           23.19   \n",
              "2727          99           0.14            9955           30.27   \n",
              "\n",
              "      Thinness_ten_nineteen_years  Thinness_five_nine_years  Schooling  \\\n",
              "107                           8.8                       8.6        8.2   \n",
              "153                           7.8                       7.6       10.1   \n",
              "159                           9.0                       8.8        7.6   \n",
              "435                           9.3                       9.1        8.0   \n",
              "513                           9.5                       9.3        8.2   \n",
              "925                           8.2                       8.0        9.8   \n",
              "1281                          8.0                       7.8       10.1   \n",
              "1289                          9.2                       8.9        7.8   \n",
              "1290                          9.7                       9.4        8.4   \n",
              "1596                          8.5                       8.3        9.4   \n",
              "1659                          8.3                       8.2        9.6   \n",
              "1834                          8.7                       8.5        8.8   \n",
              "1913                          7.6                       7.4       10.1   \n",
              "2553                          7.9                       7.7       10.1   \n",
              "2572                          9.8                       9.6        8.6   \n",
              "2727                          7.5                       7.3       10.2   \n",
              "\n",
              "      Economy_status_Developed  Economy_status_Developing  Life_expectancy  \n",
              "107                          0                          1             73.7  \n",
              "153                          0                          1             75.1  \n",
              "159                          0                          1             73.6  \n",
              "435                          0                          1             73.2  \n",
              "513                          0                          1             73.0  \n",
              "925                          0                          1             74.5  \n",
              "1281                         0                          1             74.7  \n",
              "1289                         0                          1             73.4  \n",
              "1290                         0                          1             72.8  \n",
              "1596                         0                          1             74.1  \n",
              "1659                         0                          1             74.3  \n",
              "1834                         0                          1             73.9  \n",
              "1913                         0                          1             75.3  \n",
              "2553                         0                          1             74.9  \n",
              "2572                         0                          1             72.6  \n",
              "2727                         0                          1             75.5  \n",
              "\n",
              "[16 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cffc88cb-7d16-468b-8074-4063d9881a80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Region</th>\n",
              "      <th>Year</th>\n",
              "      <th>Infant_deaths</th>\n",
              "      <th>Under_five_deaths</th>\n",
              "      <th>Adult_mortality</th>\n",
              "      <th>Alcohol_consumption</th>\n",
              "      <th>Hepatitis_B</th>\n",
              "      <th>Measles</th>\n",
              "      <th>BMI</th>\n",
              "      <th>...</th>\n",
              "      <th>Diphtheria</th>\n",
              "      <th>Incidents_HIV</th>\n",
              "      <th>GDP_per_capita</th>\n",
              "      <th>Population_mln</th>\n",
              "      <th>Thinness_ten_nineteen_years</th>\n",
              "      <th>Thinness_five_nine_years</th>\n",
              "      <th>Schooling</th>\n",
              "      <th>Economy_status_Developed</th>\n",
              "      <th>Economy_status_Developing</th>\n",
              "      <th>Life_expectancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2006</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.1</td>\n",
              "      <td>129.3760</td>\n",
              "      <td>0.45</td>\n",
              "      <td>95</td>\n",
              "      <td>90</td>\n",
              "      <td>24.6</td>\n",
              "      <td>...</td>\n",
              "      <td>95</td>\n",
              "      <td>0.20</td>\n",
              "      <td>7531</td>\n",
              "      <td>26.20</td>\n",
              "      <td>8.8</td>\n",
              "      <td>8.6</td>\n",
              "      <td>8.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>73.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2013</td>\n",
              "      <td>6.8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>124.6680</td>\n",
              "      <td>0.55</td>\n",
              "      <td>96</td>\n",
              "      <td>99</td>\n",
              "      <td>25.4</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>0.15</td>\n",
              "      <td>9179</td>\n",
              "      <td>29.47</td>\n",
              "      <td>7.8</td>\n",
              "      <td>7.6</td>\n",
              "      <td>10.1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>75.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2005</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.2</td>\n",
              "      <td>129.6545</td>\n",
              "      <td>0.49</td>\n",
              "      <td>96</td>\n",
              "      <td>91</td>\n",
              "      <td>24.5</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>0.21</td>\n",
              "      <td>7275</td>\n",
              "      <td>25.69</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>7.6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>73.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2003</td>\n",
              "      <td>7.3</td>\n",
              "      <td>8.5</td>\n",
              "      <td>130.2105</td>\n",
              "      <td>0.51</td>\n",
              "      <td>95</td>\n",
              "      <td>91</td>\n",
              "      <td>24.2</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>0.24</td>\n",
              "      <td>6728</td>\n",
              "      <td>24.70</td>\n",
              "      <td>9.3</td>\n",
              "      <td>9.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>73.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2002</td>\n",
              "      <td>7.6</td>\n",
              "      <td>8.9</td>\n",
              "      <td>130.4885</td>\n",
              "      <td>0.52</td>\n",
              "      <td>95</td>\n",
              "      <td>91</td>\n",
              "      <td>24.1</td>\n",
              "      <td>...</td>\n",
              "      <td>94</td>\n",
              "      <td>0.25</td>\n",
              "      <td>6488</td>\n",
              "      <td>24.21</td>\n",
              "      <td>9.5</td>\n",
              "      <td>9.3</td>\n",
              "      <td>8.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>73.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2010</td>\n",
              "      <td>6.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>127.3235</td>\n",
              "      <td>0.52</td>\n",
              "      <td>96</td>\n",
              "      <td>95</td>\n",
              "      <td>25.0</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>0.17</td>\n",
              "      <td>8248</td>\n",
              "      <td>28.21</td>\n",
              "      <td>8.2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1281</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2011</td>\n",
              "      <td>6.8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>126.7315</td>\n",
              "      <td>0.54</td>\n",
              "      <td>96</td>\n",
              "      <td>95</td>\n",
              "      <td>25.1</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>0.16</td>\n",
              "      <td>8550</td>\n",
              "      <td>28.65</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>10.1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1289</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2004</td>\n",
              "      <td>7.1</td>\n",
              "      <td>8.3</td>\n",
              "      <td>129.9325</td>\n",
              "      <td>0.51</td>\n",
              "      <td>94</td>\n",
              "      <td>91</td>\n",
              "      <td>24.3</td>\n",
              "      <td>...</td>\n",
              "      <td>95</td>\n",
              "      <td>0.22</td>\n",
              "      <td>7044</td>\n",
              "      <td>25.19</td>\n",
              "      <td>9.2</td>\n",
              "      <td>8.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>73.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2001</td>\n",
              "      <td>8.1</td>\n",
              "      <td>9.4</td>\n",
              "      <td>132.8190</td>\n",
              "      <td>0.52</td>\n",
              "      <td>95</td>\n",
              "      <td>91</td>\n",
              "      <td>24.0</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>0.27</td>\n",
              "      <td>6286</td>\n",
              "      <td>23.71</td>\n",
              "      <td>9.7</td>\n",
              "      <td>9.4</td>\n",
              "      <td>8.4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>72.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2008</td>\n",
              "      <td>6.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>128.5065</td>\n",
              "      <td>0.50</td>\n",
              "      <td>97</td>\n",
              "      <td>93</td>\n",
              "      <td>24.8</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>0.18</td>\n",
              "      <td>8074</td>\n",
              "      <td>27.24</td>\n",
              "      <td>8.5</td>\n",
              "      <td>8.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1659</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2009</td>\n",
              "      <td>6.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>127.9145</td>\n",
              "      <td>0.50</td>\n",
              "      <td>96</td>\n",
              "      <td>95</td>\n",
              "      <td>24.9</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>0.18</td>\n",
              "      <td>7809</td>\n",
              "      <td>27.74</td>\n",
              "      <td>8.3</td>\n",
              "      <td>8.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1834</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2007</td>\n",
              "      <td>6.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>129.0980</td>\n",
              "      <td>0.46</td>\n",
              "      <td>96</td>\n",
              "      <td>92</td>\n",
              "      <td>24.7</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>0.19</td>\n",
              "      <td>7850</td>\n",
              "      <td>26.72</td>\n",
              "      <td>8.7</td>\n",
              "      <td>8.5</td>\n",
              "      <td>8.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>73.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1913</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2014</td>\n",
              "      <td>6.8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>123.1955</td>\n",
              "      <td>0.54</td>\n",
              "      <td>96</td>\n",
              "      <td>99</td>\n",
              "      <td>25.5</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>0.15</td>\n",
              "      <td>9601</td>\n",
              "      <td>29.87</td>\n",
              "      <td>7.6</td>\n",
              "      <td>7.4</td>\n",
              "      <td>10.1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>75.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2553</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2012</td>\n",
              "      <td>6.8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>126.1405</td>\n",
              "      <td>0.55</td>\n",
              "      <td>97</td>\n",
              "      <td>99</td>\n",
              "      <td>25.3</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>0.16</td>\n",
              "      <td>8889</td>\n",
              "      <td>29.07</td>\n",
              "      <td>7.9</td>\n",
              "      <td>7.7</td>\n",
              "      <td>10.1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2572</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2000</td>\n",
              "      <td>8.7</td>\n",
              "      <td>10.2</td>\n",
              "      <td>135.1495</td>\n",
              "      <td>0.56</td>\n",
              "      <td>97</td>\n",
              "      <td>91</td>\n",
              "      <td>23.8</td>\n",
              "      <td>...</td>\n",
              "      <td>98</td>\n",
              "      <td>0.26</td>\n",
              "      <td>6393</td>\n",
              "      <td>23.19</td>\n",
              "      <td>9.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>72.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>Malaysia</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2015</td>\n",
              "      <td>6.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>121.7230</td>\n",
              "      <td>0.55</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>25.6</td>\n",
              "      <td>...</td>\n",
              "      <td>99</td>\n",
              "      <td>0.14</td>\n",
              "      <td>9955</td>\n",
              "      <td>30.27</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7.3</td>\n",
              "      <td>10.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>75.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cffc88cb-7d16-468b-8074-4063d9881a80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cffc88cb-7d16-468b-8074-4063d9881a80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cffc88cb-7d16-468b-8074-4063d9881a80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "_ti3x8-FbIN2",
        "outputId": "fe4fe780-f361-4d61-a477-cc13ba93659f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Country          Region  Year  Infant_deaths  Under_five_deaths  \\\n",
              "0  Turkiye     Middle East  2015           11.1               13.0   \n",
              "1    Spain  European Union  2015            2.7                3.3   \n",
              "2    India            Asia  2007           51.5               67.9   \n",
              "3   Guyana   South America  2006           32.8               40.5   \n",
              "4   Israel     Middle East  2012            3.4                4.3   \n",
              "\n",
              "   Adult_mortality  Alcohol_consumption  Hepatitis_B  Measles   BMI  ...  \\\n",
              "0         105.8240                 1.32           97       65  27.8  ...   \n",
              "1          57.9025                10.35           97       94  26.0  ...   \n",
              "2         201.0765                 1.57           60       35  21.2  ...   \n",
              "3         222.1965                 5.68           93       74  25.3  ...   \n",
              "4          57.9510                 2.89           97       89  27.0  ...   \n",
              "\n",
              "   Diphtheria  Incidents_HIV  GDP_per_capita  Population_mln  \\\n",
              "0          97           0.08           11006           78.53   \n",
              "1          97           0.09           25742           46.44   \n",
              "2          64           0.13            1076         1183.21   \n",
              "3          93           0.79            4146            0.75   \n",
              "4          94           0.08           33995            7.91   \n",
              "\n",
              "   Thinness_ten_nineteen_years  Thinness_five_nine_years  Schooling  \\\n",
              "0                          4.9                       4.8        7.8   \n",
              "1                          0.6                       0.5        9.7   \n",
              "2                         27.1                      28.0        5.0   \n",
              "3                          5.7                       5.5        7.9   \n",
              "4                          1.2                       1.1       12.8   \n",
              "\n",
              "   Economy_status_Developed  Economy_status_Developing  Life_expectancy  \n",
              "0                         0                          1             76.5  \n",
              "1                         1                          0             82.8  \n",
              "2                         0                          1             65.4  \n",
              "3                         0                          1             67.0  \n",
              "4                         1                          0             81.7  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-763da21e-a2c8-4303-97ce-cb5664cec2c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Region</th>\n",
              "      <th>Year</th>\n",
              "      <th>Infant_deaths</th>\n",
              "      <th>Under_five_deaths</th>\n",
              "      <th>Adult_mortality</th>\n",
              "      <th>Alcohol_consumption</th>\n",
              "      <th>Hepatitis_B</th>\n",
              "      <th>Measles</th>\n",
              "      <th>BMI</th>\n",
              "      <th>...</th>\n",
              "      <th>Diphtheria</th>\n",
              "      <th>Incidents_HIV</th>\n",
              "      <th>GDP_per_capita</th>\n",
              "      <th>Population_mln</th>\n",
              "      <th>Thinness_ten_nineteen_years</th>\n",
              "      <th>Thinness_five_nine_years</th>\n",
              "      <th>Schooling</th>\n",
              "      <th>Economy_status_Developed</th>\n",
              "      <th>Economy_status_Developing</th>\n",
              "      <th>Life_expectancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Turkiye</td>\n",
              "      <td>Middle East</td>\n",
              "      <td>2015</td>\n",
              "      <td>11.1</td>\n",
              "      <td>13.0</td>\n",
              "      <td>105.8240</td>\n",
              "      <td>1.32</td>\n",
              "      <td>97</td>\n",
              "      <td>65</td>\n",
              "      <td>27.8</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>0.08</td>\n",
              "      <td>11006</td>\n",
              "      <td>78.53</td>\n",
              "      <td>4.9</td>\n",
              "      <td>4.8</td>\n",
              "      <td>7.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>76.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Spain</td>\n",
              "      <td>European Union</td>\n",
              "      <td>2015</td>\n",
              "      <td>2.7</td>\n",
              "      <td>3.3</td>\n",
              "      <td>57.9025</td>\n",
              "      <td>10.35</td>\n",
              "      <td>97</td>\n",
              "      <td>94</td>\n",
              "      <td>26.0</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>0.09</td>\n",
              "      <td>25742</td>\n",
              "      <td>46.44</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>9.7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>82.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>India</td>\n",
              "      <td>Asia</td>\n",
              "      <td>2007</td>\n",
              "      <td>51.5</td>\n",
              "      <td>67.9</td>\n",
              "      <td>201.0765</td>\n",
              "      <td>1.57</td>\n",
              "      <td>60</td>\n",
              "      <td>35</td>\n",
              "      <td>21.2</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>0.13</td>\n",
              "      <td>1076</td>\n",
              "      <td>1183.21</td>\n",
              "      <td>27.1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>65.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Guyana</td>\n",
              "      <td>South America</td>\n",
              "      <td>2006</td>\n",
              "      <td>32.8</td>\n",
              "      <td>40.5</td>\n",
              "      <td>222.1965</td>\n",
              "      <td>5.68</td>\n",
              "      <td>93</td>\n",
              "      <td>74</td>\n",
              "      <td>25.3</td>\n",
              "      <td>...</td>\n",
              "      <td>93</td>\n",
              "      <td>0.79</td>\n",
              "      <td>4146</td>\n",
              "      <td>0.75</td>\n",
              "      <td>5.7</td>\n",
              "      <td>5.5</td>\n",
              "      <td>7.9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Israel</td>\n",
              "      <td>Middle East</td>\n",
              "      <td>2012</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.3</td>\n",
              "      <td>57.9510</td>\n",
              "      <td>2.89</td>\n",
              "      <td>97</td>\n",
              "      <td>89</td>\n",
              "      <td>27.0</td>\n",
              "      <td>...</td>\n",
              "      <td>94</td>\n",
              "      <td>0.08</td>\n",
              "      <td>33995</td>\n",
              "      <td>7.91</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.1</td>\n",
              "      <td>12.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>81.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-763da21e-a2c8-4303-97ce-cb5664cec2c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-763da21e-a2c8-4303-97ce-cb5664cec2c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-763da21e-a2c8-4303-97ce-cb5664cec2c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Life-Expectancy-Data-Updated.csv\")\n",
        "\n",
        "# Preprocessing\n",
        "# Convert categorical columns using LabelEncoder\n",
        "le_country = LabelEncoder()\n",
        "le_region = LabelEncoder()\n",
        "data['Country'] = le_country.fit_transform(data['Country'])\n",
        "data['Region'] = le_region.fit_transform(data['Region'])\n",
        "\n",
        "# Split data into features and target\n",
        "X = data.drop('Life_expectancy', axis=1)\n",
        "y = data['Life_expectancy']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "kEzrySUMcsKn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the TensorFlow model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3fWmTSlc3b6",
        "outputId": "995bc3f8-0d99-4082-a6a2-9d9c9417c602"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "65/65 [==============================] - 1s 6ms/step - loss: 2609.0359 - mae: 45.3583 - val_loss: 155.9384 - val_mae: 9.5859\n",
            "Epoch 2/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 179.4730 - mae: 10.6876 - val_loss: 62.5074 - val_mae: 6.3176\n",
            "Epoch 3/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 167.8121 - mae: 10.4658 - val_loss: 40.4794 - val_mae: 4.9162\n",
            "Epoch 4/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 153.7446 - mae: 9.8564 - val_loss: 37.3161 - val_mae: 4.7500\n",
            "Epoch 5/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 136.0828 - mae: 9.3435 - val_loss: 28.1516 - val_mae: 4.1948\n",
            "Epoch 6/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 135.7889 - mae: 9.4230 - val_loss: 26.7964 - val_mae: 4.1675\n",
            "Epoch 7/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 122.0017 - mae: 8.7657 - val_loss: 20.8832 - val_mae: 3.6723\n",
            "Epoch 8/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 114.7983 - mae: 8.4858 - val_loss: 15.7979 - val_mae: 3.1892\n",
            "Epoch 9/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 111.0802 - mae: 8.4048 - val_loss: 17.5588 - val_mae: 3.3675\n",
            "Epoch 10/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 107.7570 - mae: 8.3653 - val_loss: 14.8413 - val_mae: 3.1132\n",
            "Epoch 11/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 105.0446 - mae: 8.1968 - val_loss: 14.3667 - val_mae: 3.0823\n",
            "Epoch 12/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 105.3792 - mae: 8.1034 - val_loss: 11.7761 - val_mae: 2.7907\n",
            "Epoch 13/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 104.9004 - mae: 8.1827 - val_loss: 8.7662 - val_mae: 2.3965\n",
            "Epoch 14/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 106.3334 - mae: 8.2264 - val_loss: 14.0787 - val_mae: 3.1164\n",
            "Epoch 15/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 97.7802 - mae: 7.8029 - val_loss: 7.9305 - val_mae: 2.2819\n",
            "Epoch 16/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 93.4651 - mae: 7.6403 - val_loss: 9.2891 - val_mae: 2.5173\n",
            "Epoch 17/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 94.0887 - mae: 7.7316 - val_loss: 18.0452 - val_mae: 3.6414\n",
            "Epoch 18/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 94.2413 - mae: 7.7176 - val_loss: 6.8656 - val_mae: 2.1425\n",
            "Epoch 19/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 98.6039 - mae: 7.9054 - val_loss: 7.5290 - val_mae: 2.2320\n",
            "Epoch 20/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 97.3786 - mae: 7.8415 - val_loss: 13.4124 - val_mae: 3.1325\n",
            "Epoch 21/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 94.1067 - mae: 7.7094 - val_loss: 5.8253 - val_mae: 1.9633\n",
            "Epoch 22/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 95.5247 - mae: 7.8069 - val_loss: 6.8342 - val_mae: 2.2172\n",
            "Epoch 23/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 93.3409 - mae: 7.6711 - val_loss: 4.0188 - val_mae: 1.6107\n",
            "Epoch 24/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 89.8794 - mae: 7.6213 - val_loss: 3.6524 - val_mae: 1.5098\n",
            "Epoch 25/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 91.6180 - mae: 7.6676 - val_loss: 6.8011 - val_mae: 2.2209\n",
            "Epoch 26/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 91.2431 - mae: 7.6073 - val_loss: 3.7598 - val_mae: 1.4904\n",
            "Epoch 27/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 86.3960 - mae: 7.3407 - val_loss: 3.4262 - val_mae: 1.4656\n",
            "Epoch 28/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 85.2488 - mae: 7.2751 - val_loss: 7.9798 - val_mae: 2.4065\n",
            "Epoch 29/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 94.2385 - mae: 7.7826 - val_loss: 4.2496 - val_mae: 1.6353\n",
            "Epoch 30/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 90.6448 - mae: 7.5098 - val_loss: 3.0545 - val_mae: 1.3771\n",
            "Epoch 31/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 88.6995 - mae: 7.5172 - val_loss: 3.8645 - val_mae: 1.5734\n",
            "Epoch 32/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 94.6706 - mae: 7.7095 - val_loss: 3.9762 - val_mae: 1.6167\n",
            "Epoch 33/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 91.0591 - mae: 7.5408 - val_loss: 2.7951 - val_mae: 1.3222\n",
            "Epoch 34/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 88.9454 - mae: 7.5061 - val_loss: 5.1478 - val_mae: 1.9480\n",
            "Epoch 35/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 78.5352 - mae: 7.0946 - val_loss: 4.9549 - val_mae: 1.9069\n",
            "Epoch 36/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 93.1226 - mae: 7.6810 - val_loss: 3.9238 - val_mae: 1.6335\n",
            "Epoch 37/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 86.5793 - mae: 7.4304 - val_loss: 4.1412 - val_mae: 1.7284\n",
            "Epoch 38/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 87.8557 - mae: 7.4704 - val_loss: 8.4483 - val_mae: 2.5433\n",
            "Epoch 39/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 88.9984 - mae: 7.4906 - val_loss: 7.1006 - val_mae: 2.3500\n",
            "Epoch 40/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 82.4601 - mae: 7.1994 - val_loss: 22.6012 - val_mae: 4.4855\n",
            "Epoch 41/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 85.8817 - mae: 7.3098 - val_loss: 3.8575 - val_mae: 1.5411\n",
            "Epoch 42/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 87.1081 - mae: 7.3348 - val_loss: 13.4538 - val_mae: 3.3411\n",
            "Epoch 43/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 81.2932 - mae: 7.2039 - val_loss: 4.7392 - val_mae: 1.8678\n",
            "Epoch 44/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 89.4996 - mae: 7.5098 - val_loss: 6.5388 - val_mae: 2.2342\n",
            "Epoch 45/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 82.8071 - mae: 7.1872 - val_loss: 2.8044 - val_mae: 1.3347\n",
            "Epoch 46/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 81.5134 - mae: 7.1852 - val_loss: 2.1366 - val_mae: 1.1812\n",
            "Epoch 47/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 80.2395 - mae: 7.0544 - val_loss: 10.2342 - val_mae: 2.8608\n",
            "Epoch 48/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 82.4915 - mae: 7.2726 - val_loss: 2.4185 - val_mae: 1.2931\n",
            "Epoch 49/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 84.8436 - mae: 7.3033 - val_loss: 4.0295 - val_mae: 1.6647\n",
            "Epoch 50/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 83.9998 - mae: 7.1708 - val_loss: 8.0253 - val_mae: 2.4947\n",
            "Epoch 51/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 86.8404 - mae: 7.3790 - val_loss: 4.7491 - val_mae: 1.8448\n",
            "Epoch 52/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 84.8174 - mae: 7.2232 - val_loss: 2.4490 - val_mae: 1.2491\n",
            "Epoch 53/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 84.2786 - mae: 7.2957 - val_loss: 8.1123 - val_mae: 2.5077\n",
            "Epoch 54/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 76.7561 - mae: 7.0100 - val_loss: 2.6090 - val_mae: 1.2660\n",
            "Epoch 55/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 87.5415 - mae: 7.3960 - val_loss: 5.3744 - val_mae: 2.0408\n",
            "Epoch 56/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 81.6948 - mae: 7.2084 - val_loss: 3.5774 - val_mae: 1.5711\n",
            "Epoch 57/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 82.6206 - mae: 7.2461 - val_loss: 2.5947 - val_mae: 1.3373\n",
            "Epoch 58/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 81.4777 - mae: 7.1181 - val_loss: 2.3421 - val_mae: 1.1561\n",
            "Epoch 59/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 84.6445 - mae: 7.2034 - val_loss: 6.1883 - val_mae: 2.1207\n",
            "Epoch 60/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 75.7034 - mae: 6.8595 - val_loss: 3.1226 - val_mae: 1.4263\n",
            "Epoch 61/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 79.5482 - mae: 6.9980 - val_loss: 12.7901 - val_mae: 3.3222\n",
            "Epoch 62/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 86.8627 - mae: 7.4356 - val_loss: 2.5981 - val_mae: 1.3266\n",
            "Epoch 63/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 75.0231 - mae: 6.9190 - val_loss: 1.9037 - val_mae: 1.0528\n",
            "Epoch 64/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 80.1151 - mae: 7.0290 - val_loss: 2.4960 - val_mae: 1.2454\n",
            "Epoch 65/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 78.8181 - mae: 7.0723 - val_loss: 7.6509 - val_mae: 2.4269\n",
            "Epoch 66/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 80.5681 - mae: 7.1228 - val_loss: 5.5709 - val_mae: 2.0073\n",
            "Epoch 67/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 80.2169 - mae: 7.1630 - val_loss: 6.5557 - val_mae: 2.2757\n",
            "Epoch 68/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 80.2220 - mae: 7.0893 - val_loss: 3.1354 - val_mae: 1.4716\n",
            "Epoch 69/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 78.4740 - mae: 7.0251 - val_loss: 4.0316 - val_mae: 1.6995\n",
            "Epoch 70/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 79.2398 - mae: 7.0546 - val_loss: 4.1724 - val_mae: 1.7486\n",
            "Epoch 71/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 80.3235 - mae: 7.1901 - val_loss: 6.8029 - val_mae: 2.3326\n",
            "Epoch 72/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 79.7787 - mae: 7.0879 - val_loss: 1.7926 - val_mae: 1.1299\n",
            "Epoch 73/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 75.2798 - mae: 6.8888 - val_loss: 3.7999 - val_mae: 1.6135\n",
            "Epoch 74/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 79.9285 - mae: 7.0686 - val_loss: 1.9456 - val_mae: 1.0910\n",
            "Epoch 75/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 74.6292 - mae: 6.8066 - val_loss: 7.4689 - val_mae: 2.4189\n",
            "Epoch 76/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 77.9820 - mae: 6.8983 - val_loss: 3.3872 - val_mae: 1.5054\n",
            "Epoch 77/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 73.3022 - mae: 6.7971 - val_loss: 1.7449 - val_mae: 1.0314\n",
            "Epoch 78/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 73.3943 - mae: 6.7552 - val_loss: 2.7778 - val_mae: 1.3884\n",
            "Epoch 79/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 80.2710 - mae: 7.1500 - val_loss: 3.0504 - val_mae: 1.4319\n",
            "Epoch 80/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 77.1649 - mae: 6.8857 - val_loss: 4.6139 - val_mae: 1.7780\n",
            "Epoch 81/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 75.8209 - mae: 6.8819 - val_loss: 2.1518 - val_mae: 1.1963\n",
            "Epoch 82/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 78.5831 - mae: 6.9718 - val_loss: 2.4136 - val_mae: 1.2729\n",
            "Epoch 83/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 73.7325 - mae: 6.8544 - val_loss: 3.4182 - val_mae: 1.5937\n",
            "Epoch 84/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 74.0674 - mae: 6.8570 - val_loss: 1.6418 - val_mae: 1.0359\n",
            "Epoch 85/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 72.4701 - mae: 6.6770 - val_loss: 14.1257 - val_mae: 3.5061\n",
            "Epoch 86/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 73.1654 - mae: 6.7287 - val_loss: 1.5787 - val_mae: 1.0083\n",
            "Epoch 87/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 77.9475 - mae: 7.0083 - val_loss: 6.4674 - val_mae: 2.2550\n",
            "Epoch 88/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 68.5476 - mae: 6.5601 - val_loss: 2.0195 - val_mae: 1.1132\n",
            "Epoch 89/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 74.3795 - mae: 6.8563 - val_loss: 2.1071 - val_mae: 1.1787\n",
            "Epoch 90/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 73.2528 - mae: 6.8462 - val_loss: 1.5984 - val_mae: 0.9881\n",
            "Epoch 91/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 72.8597 - mae: 6.7605 - val_loss: 2.2406 - val_mae: 1.2456\n",
            "Epoch 92/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 72.1796 - mae: 6.6512 - val_loss: 18.0911 - val_mae: 4.0201\n",
            "Epoch 93/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 76.2080 - mae: 6.9941 - val_loss: 5.5238 - val_mae: 2.0423\n",
            "Epoch 94/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 70.6870 - mae: 6.6241 - val_loss: 4.0703 - val_mae: 1.6099\n",
            "Epoch 95/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 73.9281 - mae: 6.8368 - val_loss: 9.3476 - val_mae: 2.6428\n",
            "Epoch 96/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 68.5039 - mae: 6.5307 - val_loss: 3.6373 - val_mae: 1.6268\n",
            "Epoch 97/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 68.9207 - mae: 6.5539 - val_loss: 1.9643 - val_mae: 1.1283\n",
            "Epoch 98/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 68.0535 - mae: 6.5119 - val_loss: 2.8496 - val_mae: 1.3004\n",
            "Epoch 99/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 74.6784 - mae: 6.8694 - val_loss: 3.0532 - val_mae: 1.4933\n",
            "Epoch 100/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 69.1795 - mae: 6.5631 - val_loss: 4.6158 - val_mae: 1.9025\n",
            "Epoch 101/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 70.2068 - mae: 6.6426 - val_loss: 1.8467 - val_mae: 1.0945\n",
            "Epoch 102/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 66.0870 - mae: 6.4858 - val_loss: 1.8276 - val_mae: 1.0361\n",
            "Epoch 103/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 69.1100 - mae: 6.5666 - val_loss: 1.9661 - val_mae: 1.1546\n",
            "Epoch 104/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 69.8037 - mae: 6.5880 - val_loss: 6.2075 - val_mae: 2.1658\n",
            "Epoch 105/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 72.2602 - mae: 6.7092 - val_loss: 4.5077 - val_mae: 1.8354\n",
            "Epoch 106/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 73.9601 - mae: 6.7690 - val_loss: 4.4762 - val_mae: 1.8277\n",
            "Epoch 107/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 70.8086 - mae: 6.5897 - val_loss: 2.4109 - val_mae: 1.2703\n",
            "Epoch 108/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 70.2166 - mae: 6.6378 - val_loss: 2.0242 - val_mae: 1.1481\n",
            "Epoch 109/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 71.3105 - mae: 6.6450 - val_loss: 2.8300 - val_mae: 1.4026\n",
            "Epoch 110/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 66.8656 - mae: 6.5293 - val_loss: 2.3999 - val_mae: 1.2553\n",
            "Epoch 111/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 64.8021 - mae: 6.3021 - val_loss: 2.3241 - val_mae: 1.2468\n",
            "Epoch 112/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 67.2326 - mae: 6.5096 - val_loss: 5.0291 - val_mae: 1.9127\n",
            "Epoch 113/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 64.1939 - mae: 6.3603 - val_loss: 1.8225 - val_mae: 1.0574\n",
            "Epoch 114/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 67.4731 - mae: 6.5108 - val_loss: 2.6410 - val_mae: 1.2348\n",
            "Epoch 115/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 70.0791 - mae: 6.5220 - val_loss: 2.5885 - val_mae: 1.2778\n",
            "Epoch 116/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 62.3930 - mae: 6.2719 - val_loss: 7.2543 - val_mae: 2.3471\n",
            "Epoch 117/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 66.7014 - mae: 6.3823 - val_loss: 1.9978 - val_mae: 1.1277\n",
            "Epoch 118/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 67.7728 - mae: 6.4774 - val_loss: 3.0650 - val_mae: 1.4614\n",
            "Epoch 119/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 59.7137 - mae: 6.1824 - val_loss: 7.7299 - val_mae: 2.4221\n",
            "Epoch 120/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 64.4952 - mae: 6.3864 - val_loss: 1.8236 - val_mae: 1.0570\n",
            "Epoch 121/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 63.4696 - mae: 6.3072 - val_loss: 1.6147 - val_mae: 1.0122\n",
            "Epoch 122/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 63.5782 - mae: 6.3395 - val_loss: 1.8119 - val_mae: 1.0845\n",
            "Epoch 123/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 60.6676 - mae: 6.1679 - val_loss: 3.1994 - val_mae: 1.5341\n",
            "Epoch 124/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 67.9974 - mae: 6.4871 - val_loss: 1.8194 - val_mae: 1.0994\n",
            "Epoch 125/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 66.5073 - mae: 6.4001 - val_loss: 1.6288 - val_mae: 1.0087\n",
            "Epoch 126/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 67.6832 - mae: 6.5344 - val_loss: 8.2379 - val_mae: 2.5205\n",
            "Epoch 127/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 64.1932 - mae: 6.3299 - val_loss: 4.1166 - val_mae: 1.6387\n",
            "Epoch 128/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 63.9161 - mae: 6.3323 - val_loss: 2.7711 - val_mae: 1.3607\n",
            "Epoch 129/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 65.1605 - mae: 6.4276 - val_loss: 2.0581 - val_mae: 1.0888\n",
            "Epoch 130/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 62.4370 - mae: 6.3121 - val_loss: 2.1089 - val_mae: 1.2159\n",
            "Epoch 131/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 60.8564 - mae: 6.1273 - val_loss: 2.7322 - val_mae: 1.3559\n",
            "Epoch 132/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 66.7132 - mae: 6.4319 - val_loss: 2.0811 - val_mae: 1.1590\n",
            "Epoch 133/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 63.3323 - mae: 6.2845 - val_loss: 10.2985 - val_mae: 2.9073\n",
            "Epoch 134/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 62.0805 - mae: 6.1437 - val_loss: 2.9023 - val_mae: 1.3932\n",
            "Epoch 135/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 62.5129 - mae: 6.2569 - val_loss: 1.9725 - val_mae: 1.0625\n",
            "Epoch 136/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 64.3742 - mae: 6.3791 - val_loss: 4.0214 - val_mae: 1.7191\n",
            "Epoch 137/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 66.9316 - mae: 6.4578 - val_loss: 2.8875 - val_mae: 1.4470\n",
            "Epoch 138/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 65.0944 - mae: 6.3895 - val_loss: 2.7351 - val_mae: 1.3835\n",
            "Epoch 139/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 66.0424 - mae: 6.4293 - val_loss: 6.4570 - val_mae: 2.2792\n",
            "Epoch 140/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 62.0574 - mae: 6.2242 - val_loss: 3.2680 - val_mae: 1.4585\n",
            "Epoch 141/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 62.5207 - mae: 6.2034 - val_loss: 1.5975 - val_mae: 1.0005\n",
            "Epoch 142/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 62.5123 - mae: 6.2556 - val_loss: 2.0637 - val_mae: 1.1800\n",
            "Epoch 143/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 66.6377 - mae: 6.4276 - val_loss: 1.6371 - val_mae: 0.9659\n",
            "Epoch 144/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 60.9291 - mae: 6.1321 - val_loss: 4.6058 - val_mae: 1.8563\n",
            "Epoch 145/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 62.1422 - mae: 6.1673 - val_loss: 3.6239 - val_mae: 1.6327\n",
            "Epoch 146/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 61.4831 - mae: 6.2509 - val_loss: 2.4807 - val_mae: 1.3170\n",
            "Epoch 147/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 64.8194 - mae: 6.3676 - val_loss: 3.9391 - val_mae: 1.6923\n",
            "Epoch 148/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 61.4546 - mae: 6.1699 - val_loss: 8.7532 - val_mae: 2.6534\n",
            "Epoch 149/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 61.1557 - mae: 6.1852 - val_loss: 9.8900 - val_mae: 2.9037\n",
            "Epoch 150/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 62.9942 - mae: 6.2770 - val_loss: 1.4452 - val_mae: 0.9144\n",
            "Epoch 151/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 61.5663 - mae: 6.2289 - val_loss: 1.5663 - val_mae: 0.9786\n",
            "Epoch 152/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 63.0609 - mae: 6.3093 - val_loss: 3.7426 - val_mae: 1.6653\n",
            "Epoch 153/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 65.1655 - mae: 6.4302 - val_loss: 2.4295 - val_mae: 1.2444\n",
            "Epoch 154/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 63.3098 - mae: 6.2694 - val_loss: 1.6549 - val_mae: 1.0229\n",
            "Epoch 155/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 59.3548 - mae: 6.1030 - val_loss: 2.5769 - val_mae: 1.2788\n",
            "Epoch 156/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 58.1698 - mae: 6.0413 - val_loss: 2.3700 - val_mae: 1.2016\n",
            "Epoch 157/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 61.0339 - mae: 6.2078 - val_loss: 1.8650 - val_mae: 1.0910\n",
            "Epoch 158/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 63.4127 - mae: 6.2303 - val_loss: 4.8465 - val_mae: 1.9534\n",
            "Epoch 159/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 60.2226 - mae: 6.2124 - val_loss: 2.8964 - val_mae: 1.3791\n",
            "Epoch 160/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 55.5640 - mae: 5.9439 - val_loss: 2.5963 - val_mae: 1.2468\n",
            "Epoch 161/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 61.8668 - mae: 6.1753 - val_loss: 1.7336 - val_mae: 1.0093\n",
            "Epoch 162/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 59.8666 - mae: 6.2221 - val_loss: 2.7494 - val_mae: 1.2681\n",
            "Epoch 163/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 58.0456 - mae: 6.0287 - val_loss: 7.9865 - val_mae: 2.5335\n",
            "Epoch 164/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 60.4305 - mae: 6.0929 - val_loss: 1.5024 - val_mae: 0.9681\n",
            "Epoch 165/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 57.6623 - mae: 6.0270 - val_loss: 1.7686 - val_mae: 1.0661\n",
            "Epoch 166/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 56.0494 - mae: 5.9298 - val_loss: 2.7280 - val_mae: 1.2883\n",
            "Epoch 167/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 59.2080 - mae: 6.0470 - val_loss: 18.3061 - val_mae: 3.9444\n",
            "Epoch 168/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 60.8936 - mae: 6.1730 - val_loss: 4.3239 - val_mae: 1.6996\n",
            "Epoch 169/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 58.6141 - mae: 6.1140 - val_loss: 2.2703 - val_mae: 1.2371\n",
            "Epoch 170/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 59.6633 - mae: 6.1116 - val_loss: 1.9172 - val_mae: 1.1207\n",
            "Epoch 171/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 59.1731 - mae: 6.1039 - val_loss: 2.3297 - val_mae: 1.2358\n",
            "Epoch 172/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 59.4090 - mae: 6.0832 - val_loss: 4.5682 - val_mae: 1.8280\n",
            "Epoch 173/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 56.6056 - mae: 5.9151 - val_loss: 5.3812 - val_mae: 2.0598\n",
            "Epoch 174/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 57.8928 - mae: 6.0163 - val_loss: 3.3960 - val_mae: 1.5305\n",
            "Epoch 175/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 57.7610 - mae: 5.9476 - val_loss: 2.2458 - val_mae: 1.1231\n",
            "Epoch 176/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 58.0436 - mae: 5.9934 - val_loss: 6.0981 - val_mae: 2.0865\n",
            "Epoch 177/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 58.0308 - mae: 5.9731 - val_loss: 1.8408 - val_mae: 1.0095\n",
            "Epoch 178/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 57.6175 - mae: 6.0190 - val_loss: 2.2933 - val_mae: 1.2213\n",
            "Epoch 179/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 57.8422 - mae: 5.9642 - val_loss: 4.3876 - val_mae: 1.8038\n",
            "Epoch 180/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 59.5860 - mae: 6.1524 - val_loss: 4.6899 - val_mae: 1.8428\n",
            "Epoch 181/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 59.6052 - mae: 6.1165 - val_loss: 3.4939 - val_mae: 1.4800\n",
            "Epoch 182/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 57.1436 - mae: 5.9814 - val_loss: 3.3397 - val_mae: 1.5293\n",
            "Epoch 183/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 58.5769 - mae: 6.0203 - val_loss: 3.3971 - val_mae: 1.5432\n",
            "Epoch 184/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 60.9478 - mae: 6.2382 - val_loss: 3.7666 - val_mae: 1.6269\n",
            "Epoch 185/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 60.1694 - mae: 6.0608 - val_loss: 2.8584 - val_mae: 1.3851\n",
            "Epoch 186/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 54.0164 - mae: 5.8319 - val_loss: 4.2140 - val_mae: 1.6304\n",
            "Epoch 187/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 58.3412 - mae: 6.0920 - val_loss: 4.6725 - val_mae: 1.8085\n",
            "Epoch 188/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 56.8769 - mae: 5.9708 - val_loss: 7.5752 - val_mae: 2.3902\n",
            "Epoch 189/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 57.4339 - mae: 5.9932 - val_loss: 2.5835 - val_mae: 1.2647\n",
            "Epoch 190/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 59.6952 - mae: 6.0994 - val_loss: 1.8129 - val_mae: 0.9934\n",
            "Epoch 191/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 56.3992 - mae: 5.8690 - val_loss: 2.7284 - val_mae: 1.3695\n",
            "Epoch 192/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 56.6922 - mae: 5.9776 - val_loss: 2.4393 - val_mae: 1.2063\n",
            "Epoch 193/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 56.3832 - mae: 5.9296 - val_loss: 2.9545 - val_mae: 1.3942\n",
            "Epoch 194/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 56.1681 - mae: 5.9633 - val_loss: 3.0750 - val_mae: 1.4674\n",
            "Epoch 195/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 53.6548 - mae: 5.8356 - val_loss: 3.3689 - val_mae: 1.4622\n",
            "Epoch 196/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 54.7232 - mae: 5.8540 - val_loss: 1.9664 - val_mae: 1.0782\n",
            "Epoch 197/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 56.0196 - mae: 5.9584 - val_loss: 7.0272 - val_mae: 2.2420\n",
            "Epoch 198/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 54.7636 - mae: 5.7807 - val_loss: 2.2983 - val_mae: 1.1204\n",
            "Epoch 199/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 50.7512 - mae: 5.6476 - val_loss: 2.2861 - val_mae: 1.1724\n",
            "Epoch 200/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 53.7304 - mae: 5.8120 - val_loss: 2.2730 - val_mae: 1.1357\n",
            "Epoch 201/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 52.8622 - mae: 5.7920 - val_loss: 3.5651 - val_mae: 1.4216\n",
            "Epoch 202/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 52.3784 - mae: 5.6944 - val_loss: 3.0694 - val_mae: 1.3939\n",
            "Epoch 203/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 55.8819 - mae: 5.8455 - val_loss: 2.7434 - val_mae: 1.2636\n",
            "Epoch 204/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 54.6249 - mae: 5.8268 - val_loss: 5.4614 - val_mae: 2.0192\n",
            "Epoch 205/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 57.1571 - mae: 5.8422 - val_loss: 5.1360 - val_mae: 1.9402\n",
            "Epoch 206/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 53.6193 - mae: 5.7519 - val_loss: 2.8547 - val_mae: 1.3578\n",
            "Epoch 207/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 53.4714 - mae: 5.7263 - val_loss: 7.5304 - val_mae: 2.4032\n",
            "Epoch 208/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 52.3923 - mae: 5.7421 - val_loss: 2.3069 - val_mae: 1.1929\n",
            "Epoch 209/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 54.7695 - mae: 5.8444 - val_loss: 2.7372 - val_mae: 1.2903\n",
            "Epoch 210/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 54.3177 - mae: 5.8270 - val_loss: 2.5257 - val_mae: 1.2532\n",
            "Epoch 211/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 57.6451 - mae: 5.9133 - val_loss: 2.7666 - val_mae: 1.3296\n",
            "Epoch 212/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 53.9913 - mae: 5.7557 - val_loss: 3.3137 - val_mae: 1.5053\n",
            "Epoch 213/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 49.1264 - mae: 5.5672 - val_loss: 1.7813 - val_mae: 0.9859\n",
            "Epoch 214/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 51.1786 - mae: 5.6188 - val_loss: 3.2571 - val_mae: 1.4444\n",
            "Epoch 215/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 55.6104 - mae: 5.8922 - val_loss: 1.9916 - val_mae: 1.0787\n",
            "Epoch 216/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 53.0668 - mae: 5.7655 - val_loss: 3.1336 - val_mae: 1.4876\n",
            "Epoch 217/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 52.1364 - mae: 5.6597 - val_loss: 4.6026 - val_mae: 1.7921\n",
            "Epoch 218/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 55.0726 - mae: 5.8722 - val_loss: 3.0168 - val_mae: 1.3030\n",
            "Epoch 219/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 51.1343 - mae: 5.6871 - val_loss: 4.7235 - val_mae: 1.8205\n",
            "Epoch 220/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 55.6873 - mae: 5.8727 - val_loss: 1.8020 - val_mae: 1.0105\n",
            "Epoch 221/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 53.6380 - mae: 5.7558 - val_loss: 6.2538 - val_mae: 2.1395\n",
            "Epoch 222/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 50.6736 - mae: 5.6427 - val_loss: 2.3591 - val_mae: 1.1354\n",
            "Epoch 223/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 52.9486 - mae: 5.7037 - val_loss: 2.4805 - val_mae: 1.2691\n",
            "Epoch 224/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 51.3076 - mae: 5.6560 - val_loss: 2.3749 - val_mae: 1.1994\n",
            "Epoch 225/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 52.5624 - mae: 5.6989 - val_loss: 6.0053 - val_mae: 2.0342\n",
            "Epoch 226/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 51.3374 - mae: 5.6807 - val_loss: 3.5049 - val_mae: 1.5426\n",
            "Epoch 227/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 52.3732 - mae: 5.7351 - val_loss: 3.4984 - val_mae: 1.5329\n",
            "Epoch 228/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 51.3531 - mae: 5.6103 - val_loss: 2.2503 - val_mae: 1.1551\n",
            "Epoch 229/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 51.1185 - mae: 5.5887 - val_loss: 3.4849 - val_mae: 1.5158\n",
            "Epoch 230/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 53.2610 - mae: 5.7160 - val_loss: 2.4432 - val_mae: 1.1339\n",
            "Epoch 231/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 52.3315 - mae: 5.6917 - val_loss: 2.9093 - val_mae: 1.3951\n",
            "Epoch 232/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 53.8261 - mae: 5.8153 - val_loss: 2.8499 - val_mae: 1.3490\n",
            "Epoch 233/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 49.9451 - mae: 5.5823 - val_loss: 7.4572 - val_mae: 2.3551\n",
            "Epoch 234/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 50.1803 - mae: 5.6030 - val_loss: 2.1966 - val_mae: 1.0800\n",
            "Epoch 235/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 49.6859 - mae: 5.5490 - val_loss: 2.6593 - val_mae: 1.3038\n",
            "Epoch 236/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 48.4057 - mae: 5.5716 - val_loss: 2.2398 - val_mae: 1.1261\n",
            "Epoch 237/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 47.9637 - mae: 5.5435 - val_loss: 4.9353 - val_mae: 1.9054\n",
            "Epoch 238/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 51.8739 - mae: 5.6272 - val_loss: 2.6040 - val_mae: 1.2006\n",
            "Epoch 239/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 51.0093 - mae: 5.6086 - val_loss: 2.7361 - val_mae: 1.2958\n",
            "Epoch 240/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 50.3992 - mae: 5.6121 - val_loss: 2.8852 - val_mae: 1.3523\n",
            "Epoch 241/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 49.5363 - mae: 5.5155 - val_loss: 4.9090 - val_mae: 1.8473\n",
            "Epoch 242/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 51.3417 - mae: 5.6589 - val_loss: 2.3401 - val_mae: 1.1302\n",
            "Epoch 243/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 49.3319 - mae: 5.5945 - val_loss: 3.6160 - val_mae: 1.5522\n",
            "Epoch 244/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 50.8709 - mae: 5.6660 - val_loss: 6.2609 - val_mae: 2.1159\n",
            "Epoch 245/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 47.8628 - mae: 5.4181 - val_loss: 3.1136 - val_mae: 1.4512\n",
            "Epoch 246/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 46.7944 - mae: 5.3797 - val_loss: 2.7033 - val_mae: 1.2833\n",
            "Epoch 247/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 49.1138 - mae: 5.6185 - val_loss: 2.4155 - val_mae: 1.1871\n",
            "Epoch 248/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 51.8807 - mae: 5.6867 - val_loss: 3.6251 - val_mae: 1.5277\n",
            "Epoch 249/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 49.5542 - mae: 5.5571 - val_loss: 3.2397 - val_mae: 1.4530\n",
            "Epoch 250/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 47.9458 - mae: 5.4609 - val_loss: 9.1888 - val_mae: 2.5614\n",
            "Epoch 251/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 46.9066 - mae: 5.3988 - val_loss: 5.4032 - val_mae: 1.9674\n",
            "Epoch 252/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 50.8377 - mae: 5.6654 - val_loss: 6.6392 - val_mae: 2.1903\n",
            "Epoch 253/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 48.4935 - mae: 5.4329 - val_loss: 5.1674 - val_mae: 1.9543\n",
            "Epoch 254/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 50.2918 - mae: 5.5804 - val_loss: 6.1071 - val_mae: 2.0529\n",
            "Epoch 255/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 49.6244 - mae: 5.5581 - val_loss: 3.6214 - val_mae: 1.5000\n",
            "Epoch 256/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 47.0447 - mae: 5.3775 - val_loss: 5.7334 - val_mae: 1.8692\n",
            "Epoch 257/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 49.3572 - mae: 5.5068 - val_loss: 3.1515 - val_mae: 1.3724\n",
            "Epoch 258/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 49.3403 - mae: 5.5702 - val_loss: 3.5667 - val_mae: 1.5313\n",
            "Epoch 259/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 46.7130 - mae: 5.3690 - val_loss: 2.3277 - val_mae: 1.1618\n",
            "Epoch 260/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 47.3871 - mae: 5.4369 - val_loss: 2.5180 - val_mae: 1.2783\n",
            "Epoch 261/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 48.6790 - mae: 5.5132 - val_loss: 3.6964 - val_mae: 1.5800\n",
            "Epoch 262/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 50.1559 - mae: 5.5110 - val_loss: 2.5451 - val_mae: 1.2400\n",
            "Epoch 263/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 47.3764 - mae: 5.4637 - val_loss: 2.0600 - val_mae: 1.1000\n",
            "Epoch 264/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 49.1607 - mae: 5.5549 - val_loss: 4.9490 - val_mae: 1.8599\n",
            "Epoch 265/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 46.0246 - mae: 5.3380 - val_loss: 2.7397 - val_mae: 1.2731\n",
            "Epoch 266/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 50.2017 - mae: 5.6062 - val_loss: 3.4884 - val_mae: 1.4597\n",
            "Epoch 267/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 49.6644 - mae: 5.5977 - val_loss: 3.1432 - val_mae: 1.4337\n",
            "Epoch 268/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 46.3243 - mae: 5.3936 - val_loss: 3.7066 - val_mae: 1.5555\n",
            "Epoch 269/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 48.0871 - mae: 5.5283 - val_loss: 4.9200 - val_mae: 1.8614\n",
            "Epoch 270/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 44.9255 - mae: 5.3290 - val_loss: 2.6387 - val_mae: 1.2555\n",
            "Epoch 271/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 47.0520 - mae: 5.4090 - val_loss: 3.6913 - val_mae: 1.5090\n",
            "Epoch 272/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 51.6506 - mae: 5.6061 - val_loss: 3.3595 - val_mae: 1.4456\n",
            "Epoch 273/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 45.2479 - mae: 5.2823 - val_loss: 2.0945 - val_mae: 1.1086\n",
            "Epoch 274/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 49.3721 - mae: 5.5109 - val_loss: 2.6317 - val_mae: 1.1858\n",
            "Epoch 275/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 47.5673 - mae: 5.3973 - val_loss: 2.3772 - val_mae: 1.1497\n",
            "Epoch 276/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 46.4820 - mae: 5.3940 - val_loss: 2.9819 - val_mae: 1.3771\n",
            "Epoch 277/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 47.4365 - mae: 5.4852 - val_loss: 2.2748 - val_mae: 1.1599\n",
            "Epoch 278/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 45.3000 - mae: 5.2972 - val_loss: 2.1461 - val_mae: 1.1129\n",
            "Epoch 279/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 45.7918 - mae: 5.3419 - val_loss: 2.9744 - val_mae: 1.3197\n",
            "Epoch 280/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 43.8288 - mae: 5.1826 - val_loss: 2.5095 - val_mae: 1.2660\n",
            "Epoch 281/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 46.2310 - mae: 5.3987 - val_loss: 2.5477 - val_mae: 1.1982\n",
            "Epoch 282/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 47.2524 - mae: 5.4223 - val_loss: 3.0146 - val_mae: 1.4342\n",
            "Epoch 283/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 47.3860 - mae: 5.4387 - val_loss: 2.3028 - val_mae: 1.1831\n",
            "Epoch 284/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 46.3218 - mae: 5.3840 - val_loss: 2.8136 - val_mae: 1.2516\n",
            "Epoch 285/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 44.9798 - mae: 5.2597 - val_loss: 2.5733 - val_mae: 1.2286\n",
            "Epoch 286/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 49.9506 - mae: 5.5883 - val_loss: 2.9293 - val_mae: 1.2531\n",
            "Epoch 287/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 47.2213 - mae: 5.3686 - val_loss: 2.3866 - val_mae: 1.1519\n",
            "Epoch 288/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 47.2748 - mae: 5.4473 - val_loss: 3.3468 - val_mae: 1.5117\n",
            "Epoch 289/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 45.8484 - mae: 5.3413 - val_loss: 4.2640 - val_mae: 1.6705\n",
            "Epoch 290/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 47.7130 - mae: 5.4418 - val_loss: 2.8106 - val_mae: 1.2785\n",
            "Epoch 291/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 45.5588 - mae: 5.3219 - val_loss: 2.7560 - val_mae: 1.2176\n",
            "Epoch 292/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 45.0000 - mae: 5.2828 - val_loss: 3.3124 - val_mae: 1.4001\n",
            "Epoch 293/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 45.1541 - mae: 5.2675 - val_loss: 2.4699 - val_mae: 1.1545\n",
            "Epoch 294/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 47.8188 - mae: 5.4451 - val_loss: 3.0285 - val_mae: 1.3345\n",
            "Epoch 295/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 45.0526 - mae: 5.2618 - val_loss: 2.4375 - val_mae: 1.1647\n",
            "Epoch 296/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 44.8413 - mae: 5.2672 - val_loss: 3.3405 - val_mae: 1.4876\n",
            "Epoch 297/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 46.7378 - mae: 5.4000 - val_loss: 4.3768 - val_mae: 1.7308\n",
            "Epoch 298/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 46.6522 - mae: 5.3744 - val_loss: 3.1159 - val_mae: 1.4082\n",
            "Epoch 299/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 44.8983 - mae: 5.2622 - val_loss: 3.8610 - val_mae: 1.6182\n",
            "Epoch 300/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 47.2274 - mae: 5.3979 - val_loss: 3.2574 - val_mae: 1.4346\n",
            "Epoch 301/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 43.6437 - mae: 5.1152 - val_loss: 3.0755 - val_mae: 1.3242\n",
            "Epoch 302/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 44.8213 - mae: 5.2594 - val_loss: 5.3467 - val_mae: 1.9496\n",
            "Epoch 303/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 46.9377 - mae: 5.4370 - val_loss: 4.1534 - val_mae: 1.6872\n",
            "Epoch 304/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 45.8128 - mae: 5.3669 - val_loss: 4.3346 - val_mae: 1.7665\n",
            "Epoch 305/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 44.4212 - mae: 5.2273 - val_loss: 3.6700 - val_mae: 1.5714\n",
            "Epoch 306/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 45.8507 - mae: 5.3133 - val_loss: 2.6174 - val_mae: 1.2239\n",
            "Epoch 307/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.8942 - mae: 5.0623 - val_loss: 3.9591 - val_mae: 1.6016\n",
            "Epoch 308/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 45.4922 - mae: 5.3237 - val_loss: 3.0408 - val_mae: 1.2887\n",
            "Epoch 309/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 45.5059 - mae: 5.2992 - val_loss: 4.0525 - val_mae: 1.6273\n",
            "Epoch 310/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 43.5893 - mae: 5.1947 - val_loss: 3.1352 - val_mae: 1.3715\n",
            "Epoch 311/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 43.7295 - mae: 5.2092 - val_loss: 2.6339 - val_mae: 1.2084\n",
            "Epoch 312/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.6833 - mae: 5.1421 - val_loss: 2.5619 - val_mae: 1.2349\n",
            "Epoch 313/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 46.0686 - mae: 5.3518 - val_loss: 2.4950 - val_mae: 1.1443\n",
            "Epoch 314/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 43.6879 - mae: 5.1876 - val_loss: 2.5708 - val_mae: 1.1617\n",
            "Epoch 315/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 46.7123 - mae: 5.3433 - val_loss: 2.8960 - val_mae: 1.2158\n",
            "Epoch 316/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 43.5945 - mae: 5.2134 - val_loss: 3.0576 - val_mae: 1.2766\n",
            "Epoch 317/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 44.2192 - mae: 5.2621 - val_loss: 2.2224 - val_mae: 1.0743\n",
            "Epoch 318/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.2584 - mae: 4.9884 - val_loss: 3.0025 - val_mae: 1.3546\n",
            "Epoch 319/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 43.2254 - mae: 5.1458 - val_loss: 3.2559 - val_mae: 1.3519\n",
            "Epoch 320/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 44.8309 - mae: 5.3027 - val_loss: 2.5724 - val_mae: 1.2203\n",
            "Epoch 321/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 44.3555 - mae: 5.2500 - val_loss: 2.5476 - val_mae: 1.1596\n",
            "Epoch 322/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 44.6881 - mae: 5.3297 - val_loss: 4.2353 - val_mae: 1.7131\n",
            "Epoch 323/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.6662 - mae: 5.1376 - val_loss: 5.4914 - val_mae: 1.9760\n",
            "Epoch 324/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 43.1077 - mae: 5.1916 - val_loss: 3.8781 - val_mae: 1.5496\n",
            "Epoch 325/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 43.0199 - mae: 5.2073 - val_loss: 2.3539 - val_mae: 1.1148\n",
            "Epoch 326/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 44.3545 - mae: 5.2004 - val_loss: 4.2845 - val_mae: 1.6783\n",
            "Epoch 327/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.8917 - mae: 5.0826 - val_loss: 2.9564 - val_mae: 1.2830\n",
            "Epoch 328/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.1273 - mae: 5.0935 - val_loss: 3.1536 - val_mae: 1.4053\n",
            "Epoch 329/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.8386 - mae: 5.0173 - val_loss: 4.4488 - val_mae: 1.7696\n",
            "Epoch 330/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 45.4703 - mae: 5.2932 - val_loss: 2.5919 - val_mae: 1.1783\n",
            "Epoch 331/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 43.5224 - mae: 5.2282 - val_loss: 3.1128 - val_mae: 1.3519\n",
            "Epoch 332/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 46.7488 - mae: 5.4049 - val_loss: 2.8021 - val_mae: 1.2906\n",
            "Epoch 333/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 43.3809 - mae: 5.2314 - val_loss: 4.7666 - val_mae: 1.7410\n",
            "Epoch 334/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 40.2474 - mae: 4.9793 - val_loss: 3.9030 - val_mae: 1.5926\n",
            "Epoch 335/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.0441 - mae: 5.0485 - val_loss: 3.0715 - val_mae: 1.3787\n",
            "Epoch 336/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.3906 - mae: 5.1253 - val_loss: 4.3256 - val_mae: 1.7253\n",
            "Epoch 337/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 44.5993 - mae: 5.2472 - val_loss: 3.8642 - val_mae: 1.5759\n",
            "Epoch 338/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 45.1059 - mae: 5.2806 - val_loss: 3.9974 - val_mae: 1.6203\n",
            "Epoch 339/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 43.0055 - mae: 5.1412 - val_loss: 4.4222 - val_mae: 1.7194\n",
            "Epoch 340/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 43.8706 - mae: 5.2457 - val_loss: 2.6430 - val_mae: 1.1991\n",
            "Epoch 341/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 41.6218 - mae: 5.0463 - val_loss: 3.4607 - val_mae: 1.4729\n",
            "Epoch 342/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 41.8950 - mae: 5.1158 - val_loss: 2.9817 - val_mae: 1.2814\n",
            "Epoch 343/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 45.3688 - mae: 5.3248 - val_loss: 2.3716 - val_mae: 1.0919\n",
            "Epoch 344/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 40.7242 - mae: 5.0664 - val_loss: 3.5035 - val_mae: 1.4930\n",
            "Epoch 345/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 44.0926 - mae: 5.2253 - val_loss: 4.3568 - val_mae: 1.7380\n",
            "Epoch 346/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 43.2109 - mae: 5.1634 - val_loss: 5.0513 - val_mae: 1.8986\n",
            "Epoch 347/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 42.4497 - mae: 5.1054 - val_loss: 3.8100 - val_mae: 1.4872\n",
            "Epoch 348/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 44.4886 - mae: 5.2862 - val_loss: 4.2637 - val_mae: 1.6574\n",
            "Epoch 349/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 40.8877 - mae: 5.0846 - val_loss: 4.4819 - val_mae: 1.7350\n",
            "Epoch 350/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 43.0526 - mae: 5.1818 - val_loss: 4.1160 - val_mae: 1.6558\n",
            "Epoch 351/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 45.1791 - mae: 5.3314 - val_loss: 3.3371 - val_mae: 1.4265\n",
            "Epoch 352/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 42.8839 - mae: 5.1952 - val_loss: 5.2703 - val_mae: 1.8966\n",
            "Epoch 353/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.5489 - mae: 5.2059 - val_loss: 5.2287 - val_mae: 1.9204\n",
            "Epoch 354/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 41.1686 - mae: 5.0398 - val_loss: 3.2475 - val_mae: 1.3881\n",
            "Epoch 355/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.7722 - mae: 5.0807 - val_loss: 3.8342 - val_mae: 1.5571\n",
            "Epoch 356/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 44.2292 - mae: 5.2506 - val_loss: 4.4969 - val_mae: 1.7505\n",
            "Epoch 357/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 42.9191 - mae: 5.2157 - val_loss: 5.4061 - val_mae: 1.9156\n",
            "Epoch 358/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.1698 - mae: 5.0156 - val_loss: 3.1046 - val_mae: 1.3653\n",
            "Epoch 359/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.5369 - mae: 5.0980 - val_loss: 2.6104 - val_mae: 1.2063\n",
            "Epoch 360/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.7833 - mae: 5.0750 - val_loss: 3.7591 - val_mae: 1.5520\n",
            "Epoch 361/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 43.5378 - mae: 5.2905 - val_loss: 3.5726 - val_mae: 1.5047\n",
            "Epoch 362/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 39.8786 - mae: 5.0042 - val_loss: 3.8583 - val_mae: 1.5551\n",
            "Epoch 363/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.9350 - mae: 5.0557 - val_loss: 2.8400 - val_mae: 1.2703\n",
            "Epoch 364/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 43.6016 - mae: 5.1888 - val_loss: 4.6347 - val_mae: 1.7712\n",
            "Epoch 365/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 41.5885 - mae: 5.1021 - val_loss: 2.8314 - val_mae: 1.2987\n",
            "Epoch 366/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.4219 - mae: 5.1171 - val_loss: 3.4162 - val_mae: 1.3866\n",
            "Epoch 367/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 43.8866 - mae: 5.2302 - val_loss: 3.0463 - val_mae: 1.2531\n",
            "Epoch 368/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.5322 - mae: 5.0612 - val_loss: 3.0255 - val_mae: 1.2469\n",
            "Epoch 369/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 37.9252 - mae: 4.8741 - val_loss: 4.2208 - val_mae: 1.6807\n",
            "Epoch 370/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 42.2355 - mae: 5.1086 - val_loss: 3.8981 - val_mae: 1.6109\n",
            "Epoch 371/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.3988 - mae: 5.1476 - val_loss: 2.6383 - val_mae: 1.1764\n",
            "Epoch 372/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.8309 - mae: 5.0916 - val_loss: 4.6509 - val_mae: 1.8029\n",
            "Epoch 373/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.2481 - mae: 5.0606 - val_loss: 2.2775 - val_mae: 1.1282\n",
            "Epoch 374/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.8092 - mae: 5.0139 - val_loss: 2.8909 - val_mae: 1.2949\n",
            "Epoch 375/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.6332 - mae: 5.1383 - val_loss: 3.6762 - val_mae: 1.5805\n",
            "Epoch 376/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 44.4816 - mae: 5.2586 - val_loss: 3.1391 - val_mae: 1.3860\n",
            "Epoch 377/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 42.4743 - mae: 5.1215 - val_loss: 5.4388 - val_mae: 1.9504\n",
            "Epoch 378/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 40.2934 - mae: 4.9124 - val_loss: 3.2850 - val_mae: 1.3368\n",
            "Epoch 379/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.4399 - mae: 5.0484 - val_loss: 4.0909 - val_mae: 1.4844\n",
            "Epoch 380/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.6717 - mae: 5.1128 - val_loss: 3.0002 - val_mae: 1.3040\n",
            "Epoch 381/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.1383 - mae: 4.9242 - val_loss: 4.9723 - val_mae: 1.8677\n",
            "Epoch 382/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 38.9743 - mae: 4.9489 - val_loss: 2.7074 - val_mae: 1.1823\n",
            "Epoch 383/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.2061 - mae: 5.1126 - val_loss: 2.7051 - val_mae: 1.2200\n",
            "Epoch 384/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.0122 - mae: 4.9997 - val_loss: 3.8665 - val_mae: 1.6267\n",
            "Epoch 385/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.3694 - mae: 5.0840 - val_loss: 2.6637 - val_mae: 1.2259\n",
            "Epoch 386/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.2822 - mae: 5.2008 - val_loss: 3.3555 - val_mae: 1.4760\n",
            "Epoch 387/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 40.4574 - mae: 5.0223 - val_loss: 6.1414 - val_mae: 2.1116\n",
            "Epoch 388/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 38.7193 - mae: 4.9180 - val_loss: 2.9534 - val_mae: 1.2811\n",
            "Epoch 389/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.8805 - mae: 5.1641 - val_loss: 2.9761 - val_mae: 1.2482\n",
            "Epoch 390/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.6369 - mae: 5.0547 - val_loss: 3.2069 - val_mae: 1.3746\n",
            "Epoch 391/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.2704 - mae: 4.9356 - val_loss: 2.8039 - val_mae: 1.1684\n",
            "Epoch 392/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.0564 - mae: 5.0537 - val_loss: 3.2757 - val_mae: 1.3012\n",
            "Epoch 393/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 42.3410 - mae: 5.1697 - val_loss: 3.2902 - val_mae: 1.3779\n",
            "Epoch 394/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 40.5904 - mae: 5.0145 - val_loss: 4.3100 - val_mae: 1.5712\n",
            "Epoch 395/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 40.0486 - mae: 5.0082 - val_loss: 5.2115 - val_mae: 1.8812\n",
            "Epoch 396/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 41.4756 - mae: 5.0615 - val_loss: 2.9969 - val_mae: 1.3038\n",
            "Epoch 397/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 38.8462 - mae: 4.9054 - val_loss: 2.9970 - val_mae: 1.2560\n",
            "Epoch 398/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 39.4602 - mae: 4.9964 - val_loss: 2.4400 - val_mae: 1.1341\n",
            "Epoch 399/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 37.4769 - mae: 4.8247 - val_loss: 3.5669 - val_mae: 1.3257\n",
            "Epoch 400/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.8817 - mae: 5.0032 - val_loss: 3.3030 - val_mae: 1.3298\n",
            "Epoch 401/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 39.1826 - mae: 4.9442 - val_loss: 3.8090 - val_mae: 1.5499\n",
            "Epoch 402/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 41.0763 - mae: 5.0532 - val_loss: 2.8397 - val_mae: 1.2551\n",
            "Epoch 403/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 38.9299 - mae: 4.9841 - val_loss: 3.1649 - val_mae: 1.2909\n",
            "Epoch 404/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 42.0130 - mae: 5.1289 - val_loss: 2.5478 - val_mae: 1.1137\n",
            "Epoch 405/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.1979 - mae: 5.0162 - val_loss: 2.8632 - val_mae: 1.1630\n",
            "Epoch 406/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 39.8325 - mae: 4.9577 - val_loss: 3.1216 - val_mae: 1.2794\n",
            "Epoch 407/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.2661 - mae: 5.0249 - val_loss: 3.2684 - val_mae: 1.3981\n",
            "Epoch 408/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 39.1745 - mae: 4.9346 - val_loss: 3.2388 - val_mae: 1.2649\n",
            "Epoch 409/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 39.5187 - mae: 4.9819 - val_loss: 3.0554 - val_mae: 1.2804\n",
            "Epoch 410/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 38.9156 - mae: 5.0115 - val_loss: 3.6246 - val_mae: 1.4178\n",
            "Epoch 411/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.9702 - mae: 4.8604 - val_loss: 4.1083 - val_mae: 1.6549\n",
            "Epoch 412/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.7433 - mae: 5.0170 - val_loss: 3.8775 - val_mae: 1.5309\n",
            "Epoch 413/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.9942 - mae: 5.0427 - val_loss: 3.7327 - val_mae: 1.3689\n",
            "Epoch 414/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 37.9144 - mae: 4.8632 - val_loss: 2.9205 - val_mae: 1.2834\n",
            "Epoch 415/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.0271 - mae: 4.9580 - val_loss: 4.2542 - val_mae: 1.6689\n",
            "Epoch 416/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.5235 - mae: 5.0819 - val_loss: 2.6693 - val_mae: 1.1325\n",
            "Epoch 417/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 38.7508 - mae: 4.8936 - val_loss: 3.1674 - val_mae: 1.3071\n",
            "Epoch 418/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.5323 - mae: 5.0487 - val_loss: 3.3471 - val_mae: 1.4022\n",
            "Epoch 419/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 40.9995 - mae: 4.9916 - val_loss: 2.2364 - val_mae: 1.1583\n",
            "Epoch 420/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 39.6063 - mae: 4.9610 - val_loss: 3.8700 - val_mae: 1.5735\n",
            "Epoch 421/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.2796 - mae: 4.9192 - val_loss: 3.9739 - val_mae: 1.5135\n",
            "Epoch 422/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 38.5200 - mae: 4.9350 - val_loss: 5.3221 - val_mae: 1.9329\n",
            "Epoch 423/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 39.8097 - mae: 4.9609 - val_loss: 2.3001 - val_mae: 1.1433\n",
            "Epoch 424/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 41.5123 - mae: 5.0953 - val_loss: 3.7142 - val_mae: 1.4866\n",
            "Epoch 425/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 38.3262 - mae: 4.8406 - val_loss: 2.6506 - val_mae: 1.2404\n",
            "Epoch 426/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 38.5081 - mae: 4.8565 - val_loss: 3.9589 - val_mae: 1.5237\n",
            "Epoch 427/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.9416 - mae: 4.8700 - val_loss: 3.1406 - val_mae: 1.2471\n",
            "Epoch 428/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 39.2668 - mae: 4.9537 - val_loss: 3.8933 - val_mae: 1.3870\n",
            "Epoch 429/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 39.2166 - mae: 4.9610 - val_loss: 2.6544 - val_mae: 1.1553\n",
            "Epoch 430/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.8574 - mae: 4.8126 - val_loss: 3.6238 - val_mae: 1.4061\n",
            "Epoch 431/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 42.1047 - mae: 5.1197 - val_loss: 5.0217 - val_mae: 1.8182\n",
            "Epoch 432/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 41.3227 - mae: 5.1033 - val_loss: 3.7139 - val_mae: 1.4674\n",
            "Epoch 433/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.8004 - mae: 4.9592 - val_loss: 3.6876 - val_mae: 1.4765\n",
            "Epoch 434/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.0971 - mae: 4.8931 - val_loss: 2.6943 - val_mae: 1.1807\n",
            "Epoch 435/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 38.5728 - mae: 4.8712 - val_loss: 3.9580 - val_mae: 1.5983\n",
            "Epoch 436/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.3823 - mae: 4.9277 - val_loss: 3.3434 - val_mae: 1.4554\n",
            "Epoch 437/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 36.3696 - mae: 4.7585 - val_loss: 5.2636 - val_mae: 1.9053\n",
            "Epoch 438/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.6255 - mae: 4.9807 - val_loss: 4.2131 - val_mae: 1.5710\n",
            "Epoch 439/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 37.0224 - mae: 4.8271 - val_loss: 4.5882 - val_mae: 1.8096\n",
            "Epoch 440/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 38.7960 - mae: 4.8853 - val_loss: 2.1488 - val_mae: 1.0586\n",
            "Epoch 441/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.3146 - mae: 4.9171 - val_loss: 3.7997 - val_mae: 1.3236\n",
            "Epoch 442/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.6383 - mae: 4.9640 - val_loss: 2.5025 - val_mae: 1.1644\n",
            "Epoch 443/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.2940 - mae: 4.9916 - val_loss: 3.1081 - val_mae: 1.3272\n",
            "Epoch 444/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.6529 - mae: 4.9561 - val_loss: 3.0542 - val_mae: 1.3114\n",
            "Epoch 445/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.2109 - mae: 4.8055 - val_loss: 3.4213 - val_mae: 1.3546\n",
            "Epoch 446/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 38.9019 - mae: 4.9075 - val_loss: 3.3244 - val_mae: 1.4696\n",
            "Epoch 447/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.2201 - mae: 4.8988 - val_loss: 4.2091 - val_mae: 1.5219\n",
            "Epoch 448/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.4375 - mae: 4.9474 - val_loss: 11.2178 - val_mae: 2.8332\n",
            "Epoch 449/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.6190 - mae: 5.0185 - val_loss: 2.9249 - val_mae: 1.2592\n",
            "Epoch 450/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.3308 - mae: 4.7938 - val_loss: 3.5072 - val_mae: 1.4177\n",
            "Epoch 451/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 36.7493 - mae: 4.7563 - val_loss: 3.5734 - val_mae: 1.4973\n",
            "Epoch 452/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 38.2574 - mae: 4.9359 - val_loss: 2.3904 - val_mae: 1.2036\n",
            "Epoch 453/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 37.7544 - mae: 4.8859 - val_loss: 3.6282 - val_mae: 1.4147\n",
            "Epoch 454/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 38.9074 - mae: 4.9256 - val_loss: 3.0383 - val_mae: 1.2391\n",
            "Epoch 455/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 38.8160 - mae: 4.9372 - val_loss: 2.8403 - val_mae: 1.2476\n",
            "Epoch 456/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 37.6206 - mae: 4.8762 - val_loss: 2.5894 - val_mae: 1.1182\n",
            "Epoch 457/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 37.7662 - mae: 4.8682 - val_loss: 3.3142 - val_mae: 1.2294\n",
            "Epoch 458/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 40.6243 - mae: 5.0099 - val_loss: 2.5616 - val_mae: 1.2245\n",
            "Epoch 459/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 39.9721 - mae: 5.0213 - val_loss: 2.9204 - val_mae: 1.2892\n",
            "Epoch 460/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 37.1696 - mae: 4.7754 - val_loss: 4.1927 - val_mae: 1.6436\n",
            "Epoch 461/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 38.8519 - mae: 4.9303 - val_loss: 4.5456 - val_mae: 1.7599\n",
            "Epoch 462/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 37.7542 - mae: 4.8053 - val_loss: 2.9355 - val_mae: 1.1859\n",
            "Epoch 463/500\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 37.8965 - mae: 4.9145 - val_loss: 3.6965 - val_mae: 1.3585\n",
            "Epoch 464/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 35.1316 - mae: 4.6901 - val_loss: 4.5524 - val_mae: 1.6894\n",
            "Epoch 465/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 38.5509 - mae: 4.9428 - val_loss: 3.6783 - val_mae: 1.5289\n",
            "Epoch 466/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 38.8739 - mae: 4.8984 - val_loss: 3.0587 - val_mae: 1.2531\n",
            "Epoch 467/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 38.1114 - mae: 4.8893 - val_loss: 3.7758 - val_mae: 1.2758\n",
            "Epoch 468/500\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 39.4351 - mae: 4.9831 - val_loss: 3.3305 - val_mae: 1.4232\n",
            "Epoch 469/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 40.0282 - mae: 4.9747 - val_loss: 3.0299 - val_mae: 1.3679\n",
            "Epoch 470/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.0124 - mae: 4.7951 - val_loss: 3.2655 - val_mae: 1.3626\n",
            "Epoch 471/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 37.7617 - mae: 4.8460 - val_loss: 3.7128 - val_mae: 1.4286\n",
            "Epoch 472/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.3272 - mae: 4.9606 - val_loss: 5.7027 - val_mae: 2.0187\n",
            "Epoch 473/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.3073 - mae: 4.8491 - val_loss: 2.7429 - val_mae: 1.2346\n",
            "Epoch 474/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.0519 - mae: 5.0873 - val_loss: 4.3955 - val_mae: 1.7323\n",
            "Epoch 475/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 37.9986 - mae: 4.8570 - val_loss: 2.3362 - val_mae: 1.0804\n",
            "Epoch 476/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 38.5116 - mae: 4.8591 - val_loss: 3.5770 - val_mae: 1.3467\n",
            "Epoch 477/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.7406 - mae: 4.8090 - val_loss: 2.5664 - val_mae: 1.1807\n",
            "Epoch 478/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 36.8083 - mae: 4.8157 - val_loss: 3.0852 - val_mae: 1.2719\n",
            "Epoch 479/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 36.7161 - mae: 4.7777 - val_loss: 3.3936 - val_mae: 1.3886\n",
            "Epoch 480/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 41.0770 - mae: 5.0084 - val_loss: 4.5134 - val_mae: 1.6651\n",
            "Epoch 481/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 39.7440 - mae: 5.0006 - val_loss: 4.6702 - val_mae: 1.7447\n",
            "Epoch 482/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.4368 - mae: 4.8479 - val_loss: 3.7940 - val_mae: 1.4062\n",
            "Epoch 483/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.8144 - mae: 4.8324 - val_loss: 3.2847 - val_mae: 1.4333\n",
            "Epoch 484/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 38.1716 - mae: 4.9028 - val_loss: 2.9878 - val_mae: 1.2195\n",
            "Epoch 485/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 35.0410 - mae: 4.6759 - val_loss: 3.4166 - val_mae: 1.3930\n",
            "Epoch 486/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 36.2373 - mae: 4.7217 - val_loss: 3.3201 - val_mae: 1.4421\n",
            "Epoch 487/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.1746 - mae: 4.7411 - val_loss: 2.6472 - val_mae: 1.1510\n",
            "Epoch 488/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 35.1735 - mae: 4.6768 - val_loss: 5.4796 - val_mae: 1.9720\n",
            "Epoch 489/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 36.4310 - mae: 4.7879 - val_loss: 3.1524 - val_mae: 1.2732\n",
            "Epoch 490/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 35.7353 - mae: 4.7023 - val_loss: 3.5665 - val_mae: 1.4759\n",
            "Epoch 491/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 38.4246 - mae: 4.9173 - val_loss: 3.5023 - val_mae: 1.3656\n",
            "Epoch 492/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.9560 - mae: 4.8386 - val_loss: 2.6256 - val_mae: 1.1422\n",
            "Epoch 493/500\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 37.5905 - mae: 4.8448 - val_loss: 3.1814 - val_mae: 1.3647\n",
            "Epoch 494/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.7025 - mae: 4.8336 - val_loss: 2.2280 - val_mae: 1.0931\n",
            "Epoch 495/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.1623 - mae: 5.0106 - val_loss: 3.5721 - val_mae: 1.4431\n",
            "Epoch 496/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 36.8769 - mae: 4.7831 - val_loss: 4.4154 - val_mae: 1.7260\n",
            "Epoch 497/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 40.2816 - mae: 5.0604 - val_loss: 3.9557 - val_mae: 1.5743\n",
            "Epoch 498/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 36.7748 - mae: 4.7724 - val_loss: 4.4387 - val_mae: 1.7282\n",
            "Epoch 499/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 35.8915 - mae: 4.6626 - val_loss: 3.2787 - val_mae: 1.3032\n",
            "Epoch 500/500\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 37.0621 - mae: 4.8225 - val_loss: 3.2807 - val_mae: 1.3998\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f686b4e5ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvXHcIiYdGa-",
        "outputId": "980bb3ca-40e3-49ee-bb52-c63bccc36ddf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 3ms/step - loss: 3.0304 - mae: 1.3734\n",
            "Mean Absolute Error: 1.373362421989441\n",
            "18/18 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[71.711716],\n",
              "       [80.09347 ],\n",
              "       [64.1143  ],\n",
              "       [57.184746],\n",
              "       [77.62534 ],\n",
              "       [80.187126],\n",
              "       [78.80982 ],\n",
              "       [61.061325],\n",
              "       [68.96914 ],\n",
              "       [80.183105],\n",
              "       [62.657104],\n",
              "       [68.95328 ],\n",
              "       [81.76037 ],\n",
              "       [73.08738 ],\n",
              "       [73.15455 ],\n",
              "       [57.344193],\n",
              "       [72.85089 ],\n",
              "       [79.60027 ],\n",
              "       [76.217476],\n",
              "       [74.02283 ],\n",
              "       [78.38775 ],\n",
              "       [58.146637],\n",
              "       [70.49982 ],\n",
              "       [78.32481 ],\n",
              "       [76.86246 ],\n",
              "       [66.348526],\n",
              "       [74.400055],\n",
              "       [68.693985],\n",
              "       [57.74032 ],\n",
              "       [60.28961 ],\n",
              "       [62.362   ],\n",
              "       [74.18896 ],\n",
              "       [75.84002 ],\n",
              "       [51.051445],\n",
              "       [60.292534],\n",
              "       [70.153694],\n",
              "       [63.645775],\n",
              "       [73.01917 ],\n",
              "       [54.163437],\n",
              "       [59.831665],\n",
              "       [71.46648 ],\n",
              "       [68.73747 ],\n",
              "       [56.97145 ],\n",
              "       [63.241013],\n",
              "       [71.87389 ],\n",
              "       [66.99159 ],\n",
              "       [53.082726],\n",
              "       [57.478577],\n",
              "       [80.39442 ],\n",
              "       [69.16937 ],\n",
              "       [68.05467 ],\n",
              "       [72.13596 ],\n",
              "       [73.08265 ],\n",
              "       [74.88282 ],\n",
              "       [78.4383  ],\n",
              "       [71.75609 ],\n",
              "       [62.13697 ],\n",
              "       [71.82326 ],\n",
              "       [69.673065],\n",
              "       [64.01681 ],\n",
              "       [70.32639 ],\n",
              "       [68.0249  ],\n",
              "       [61.08542 ],\n",
              "       [75.02886 ],\n",
              "       [73.866554],\n",
              "       [78.11735 ],\n",
              "       [79.5211  ],\n",
              "       [79.19778 ],\n",
              "       [66.55152 ],\n",
              "       [78.42632 ],\n",
              "       [75.06881 ],\n",
              "       [54.851006],\n",
              "       [73.25953 ],\n",
              "       [71.244896],\n",
              "       [68.58559 ],\n",
              "       [67.701126],\n",
              "       [66.389175],\n",
              "       [66.48447 ],\n",
              "       [73.4262  ],\n",
              "       [66.04712 ],\n",
              "       [80.443726],\n",
              "       [77.08384 ],\n",
              "       [72.88466 ],\n",
              "       [72.5346  ],\n",
              "       [60.22941 ],\n",
              "       [75.42611 ],\n",
              "       [53.784195],\n",
              "       [77.24889 ],\n",
              "       [80.620056],\n",
              "       [71.11676 ],\n",
              "       [73.29153 ],\n",
              "       [54.413216],\n",
              "       [60.039825],\n",
              "       [68.64625 ],\n",
              "       [56.621895],\n",
              "       [60.878563],\n",
              "       [73.6682  ],\n",
              "       [67.98762 ],\n",
              "       [72.45176 ],\n",
              "       [68.70646 ],\n",
              "       [55.345222],\n",
              "       [68.20451 ],\n",
              "       [73.84645 ],\n",
              "       [59.843086],\n",
              "       [69.47642 ],\n",
              "       [55.937614],\n",
              "       [58.421272],\n",
              "       [58.834396],\n",
              "       [78.45435 ],\n",
              "       [58.103317],\n",
              "       [75.29601 ],\n",
              "       [74.686134],\n",
              "       [69.40677 ],\n",
              "       [54.273956],\n",
              "       [63.391426],\n",
              "       [56.74256 ],\n",
              "       [72.76203 ],\n",
              "       [74.63883 ],\n",
              "       [61.912704],\n",
              "       [68.41634 ],\n",
              "       [68.89387 ],\n",
              "       [67.53012 ],\n",
              "       [67.88571 ],\n",
              "       [63.72802 ],\n",
              "       [70.43622 ],\n",
              "       [67.06833 ],\n",
              "       [56.932045],\n",
              "       [70.37514 ],\n",
              "       [79.44669 ],\n",
              "       [64.38341 ],\n",
              "       [72.71398 ],\n",
              "       [55.371735],\n",
              "       [59.485542],\n",
              "       [70.43957 ],\n",
              "       [53.121307],\n",
              "       [73.39976 ],\n",
              "       [78.75488 ],\n",
              "       [57.81507 ],\n",
              "       [74.79485 ],\n",
              "       [71.17094 ],\n",
              "       [78.73803 ],\n",
              "       [62.673508],\n",
              "       [68.47164 ],\n",
              "       [54.544685],\n",
              "       [70.013756],\n",
              "       [69.64371 ],\n",
              "       [73.74701 ],\n",
              "       [72.97672 ],\n",
              "       [67.70715 ],\n",
              "       [72.51212 ],\n",
              "       [47.88208 ],\n",
              "       [70.368576],\n",
              "       [71.18463 ],\n",
              "       [66.98687 ],\n",
              "       [67.36249 ],\n",
              "       [72.78626 ],\n",
              "       [73.90811 ],\n",
              "       [71.796104],\n",
              "       [78.01664 ],\n",
              "       [55.01895 ],\n",
              "       [79.41208 ],\n",
              "       [64.11587 ],\n",
              "       [54.400154],\n",
              "       [76.056435],\n",
              "       [76.53507 ],\n",
              "       [75.47449 ],\n",
              "       [73.28135 ],\n",
              "       [79.03603 ],\n",
              "       [59.055115],\n",
              "       [68.625336],\n",
              "       [80.613914],\n",
              "       [54.152115],\n",
              "       [73.76198 ],\n",
              "       [71.79514 ],\n",
              "       [68.11655 ],\n",
              "       [59.999985],\n",
              "       [74.2437  ],\n",
              "       [54.689926],\n",
              "       [69.497055],\n",
              "       [61.727142],\n",
              "       [77.14242 ],\n",
              "       [77.36029 ],\n",
              "       [78.4275  ],\n",
              "       [76.80848 ],\n",
              "       [70.63104 ],\n",
              "       [60.668793],\n",
              "       [72.52315 ],\n",
              "       [58.831413],\n",
              "       [73.84463 ],\n",
              "       [65.60828 ],\n",
              "       [60.91191 ],\n",
              "       [49.648438],\n",
              "       [70.70602 ],\n",
              "       [63.854485],\n",
              "       [74.210175],\n",
              "       [71.58628 ],\n",
              "       [75.3318  ],\n",
              "       [60.766266],\n",
              "       [72.70319 ],\n",
              "       [76.46063 ],\n",
              "       [65.29389 ],\n",
              "       [51.525322],\n",
              "       [67.042244],\n",
              "       [68.15398 ],\n",
              "       [70.23822 ],\n",
              "       [78.178215],\n",
              "       [79.13633 ],\n",
              "       [70.412   ],\n",
              "       [71.96911 ],\n",
              "       [62.41001 ],\n",
              "       [75.40688 ],\n",
              "       [74.307884],\n",
              "       [72.34768 ],\n",
              "       [74.7243  ],\n",
              "       [49.30931 ],\n",
              "       [69.882545],\n",
              "       [75.11386 ],\n",
              "       [69.12425 ],\n",
              "       [59.267593],\n",
              "       [77.34405 ],\n",
              "       [59.564537],\n",
              "       [69.32647 ],\n",
              "       [72.91426 ],\n",
              "       [67.5005  ],\n",
              "       [78.79769 ],\n",
              "       [74.6781  ],\n",
              "       [59.221954],\n",
              "       [62.802025],\n",
              "       [71.160164],\n",
              "       [51.11351 ],\n",
              "       [72.59705 ],\n",
              "       [54.608467],\n",
              "       [51.8478  ],\n",
              "       [71.256035],\n",
              "       [67.47805 ],\n",
              "       [78.12701 ],\n",
              "       [70.505035],\n",
              "       [80.97306 ],\n",
              "       [59.727432],\n",
              "       [79.35526 ],\n",
              "       [79.75347 ],\n",
              "       [74.31971 ],\n",
              "       [80.8682  ],\n",
              "       [62.13816 ],\n",
              "       [71.56776 ],\n",
              "       [73.52903 ],\n",
              "       [67.417984],\n",
              "       [65.56832 ],\n",
              "       [79.26862 ],\n",
              "       [47.060616],\n",
              "       [75.93102 ],\n",
              "       [72.64355 ],\n",
              "       [68.0563  ],\n",
              "       [79.6022  ],\n",
              "       [66.7712  ],\n",
              "       [56.503777],\n",
              "       [67.33622 ],\n",
              "       [75.11489 ],\n",
              "       [71.07183 ],\n",
              "       [70.803276],\n",
              "       [67.86298 ],\n",
              "       [72.51116 ],\n",
              "       [72.91136 ],\n",
              "       [67.22714 ],\n",
              "       [74.46125 ],\n",
              "       [74.16585 ],\n",
              "       [73.60601 ],\n",
              "       [70.55834 ],\n",
              "       [78.62821 ],\n",
              "       [71.27761 ],\n",
              "       [72.76316 ],\n",
              "       [60.181877],\n",
              "       [78.29916 ],\n",
              "       [69.488815],\n",
              "       [68.00639 ],\n",
              "       [72.05564 ],\n",
              "       [68.66142 ],\n",
              "       [72.67543 ],\n",
              "       [72.95231 ],\n",
              "       [55.131195],\n",
              "       [70.02748 ],\n",
              "       [68.641785],\n",
              "       [49.500183],\n",
              "       [74.95904 ],\n",
              "       [67.90382 ],\n",
              "       [76.635284],\n",
              "       [60.250725],\n",
              "       [69.4792  ],\n",
              "       [70.90684 ],\n",
              "       [77.5126  ],\n",
              "       [81.04269 ],\n",
              "       [52.158073],\n",
              "       [72.09739 ],\n",
              "       [49.295692],\n",
              "       [72.528366],\n",
              "       [77.134445],\n",
              "       [79.537056],\n",
              "       [66.40981 ],\n",
              "       [72.41492 ],\n",
              "       [66.32512 ],\n",
              "       [75.15724 ],\n",
              "       [62.575638],\n",
              "       [66.23584 ],\n",
              "       [47.723717],\n",
              "       [71.261734],\n",
              "       [69.22411 ],\n",
              "       [55.963562],\n",
              "       [68.51175 ],\n",
              "       [67.96468 ],\n",
              "       [57.282616],\n",
              "       [48.039658],\n",
              "       [74.05765 ],\n",
              "       [49.540398],\n",
              "       [73.80867 ],\n",
              "       [60.689445],\n",
              "       [72.42667 ],\n",
              "       [67.28486 ],\n",
              "       [73.338905],\n",
              "       [60.140602],\n",
              "       [78.36743 ],\n",
              "       [69.61968 ],\n",
              "       [71.61718 ],\n",
              "       [71.03171 ],\n",
              "       [76.454796],\n",
              "       [69.990456],\n",
              "       [62.535126],\n",
              "       [69.76071 ],\n",
              "       [54.693504],\n",
              "       [70.0674  ],\n",
              "       [67.55835 ],\n",
              "       [58.40394 ],\n",
              "       [67.60319 ],\n",
              "       [76.121574],\n",
              "       [67.20917 ],\n",
              "       [81.091606],\n",
              "       [69.40986 ],\n",
              "       [70.45038 ],\n",
              "       [73.77571 ],\n",
              "       [76.50555 ],\n",
              "       [72.83222 ],\n",
              "       [69.8849  ],\n",
              "       [74.42729 ],\n",
              "       [78.36469 ],\n",
              "       [63.557076],\n",
              "       [79.46989 ],\n",
              "       [70.174774],\n",
              "       [60.01449 ],\n",
              "       [64.73718 ],\n",
              "       [70.03715 ],\n",
              "       [73.22975 ],\n",
              "       [61.791115],\n",
              "       [73.80786 ],\n",
              "       [54.58033 ],\n",
              "       [52.037384],\n",
              "       [77.903625],\n",
              "       [74.919685],\n",
              "       [72.18705 ],\n",
              "       [65.63552 ],\n",
              "       [72.86676 ],\n",
              "       [71.63762 ],\n",
              "       [67.16961 ],\n",
              "       [70.76471 ],\n",
              "       [78.032295],\n",
              "       [61.23188 ],\n",
              "       [71.11847 ],\n",
              "       [72.02186 ],\n",
              "       [70.09961 ],\n",
              "       [71.89921 ],\n",
              "       [50.37776 ],\n",
              "       [59.04516 ],\n",
              "       [60.225693],\n",
              "       [59.877052],\n",
              "       [69.350136],\n",
              "       [71.97843 ],\n",
              "       [68.43588 ],\n",
              "       [70.67185 ],\n",
              "       [75.765366],\n",
              "       [73.27109 ],\n",
              "       [61.17733 ],\n",
              "       [70.69525 ],\n",
              "       [72.78248 ],\n",
              "       [57.797493],\n",
              "       [69.71686 ],\n",
              "       [55.42182 ],\n",
              "       [49.311302],\n",
              "       [58.15764 ],\n",
              "       [76.68972 ],\n",
              "       [74.880775],\n",
              "       [72.51705 ],\n",
              "       [74.32076 ],\n",
              "       [67.44588 ],\n",
              "       [70.41052 ],\n",
              "       [72.99387 ],\n",
              "       [67.38248 ],\n",
              "       [72.18149 ],\n",
              "       [67.772026],\n",
              "       [77.679955],\n",
              "       [79.49096 ],\n",
              "       [58.56118 ],\n",
              "       [79.183876],\n",
              "       [73.0546  ],\n",
              "       [69.17889 ],\n",
              "       [71.35731 ],\n",
              "       [72.50738 ],\n",
              "       [71.67069 ],\n",
              "       [66.10295 ],\n",
              "       [60.132896],\n",
              "       [74.80508 ],\n",
              "       [65.873856],\n",
              "       [63.43393 ],\n",
              "       [69.25843 ],\n",
              "       [57.903053],\n",
              "       [72.025246],\n",
              "       [59.917908],\n",
              "       [75.06742 ],\n",
              "       [72.37597 ],\n",
              "       [74.03707 ],\n",
              "       [68.72592 ],\n",
              "       [69.34922 ],\n",
              "       [72.660904],\n",
              "       [78.67495 ],\n",
              "       [74.577736],\n",
              "       [56.44677 ],\n",
              "       [71.48305 ],\n",
              "       [77.14326 ],\n",
              "       [54.50843 ],\n",
              "       [75.63449 ],\n",
              "       [71.174515],\n",
              "       [55.35167 ],\n",
              "       [79.08378 ],\n",
              "       [58.30658 ],\n",
              "       [55.6084  ],\n",
              "       [67.8859  ],\n",
              "       [66.589905],\n",
              "       [74.00757 ],\n",
              "       [76.90321 ],\n",
              "       [58.34333 ],\n",
              "       [66.51286 ],\n",
              "       [64.64054 ],\n",
              "       [67.19563 ],\n",
              "       [69.29507 ],\n",
              "       [74.1313  ],\n",
              "       [64.905106],\n",
              "       [71.243965],\n",
              "       [73.71315 ],\n",
              "       [62.704056],\n",
              "       [72.697655],\n",
              "       [69.652336],\n",
              "       [81.492134],\n",
              "       [68.63108 ],\n",
              "       [75.668015],\n",
              "       [71.93982 ],\n",
              "       [66.64213 ],\n",
              "       [74.01738 ],\n",
              "       [71.05195 ],\n",
              "       [80.6034  ],\n",
              "       [71.77442 ],\n",
              "       [79.12533 ],\n",
              "       [78.81734 ],\n",
              "       [71.20665 ],\n",
              "       [62.37593 ],\n",
              "       [71.93919 ],\n",
              "       [57.33477 ],\n",
              "       [59.00795 ],\n",
              "       [67.43908 ],\n",
              "       [58.540115],\n",
              "       [71.22357 ],\n",
              "       [75.383354],\n",
              "       [65.04982 ],\n",
              "       [79.809074],\n",
              "       [71.31494 ],\n",
              "       [71.28552 ],\n",
              "       [69.53211 ],\n",
              "       [72.95094 ],\n",
              "       [60.07173 ],\n",
              "       [71.95358 ],\n",
              "       [76.164734],\n",
              "       [78.207344],\n",
              "       [69.46718 ],\n",
              "       [74.959305],\n",
              "       [69.12671 ],\n",
              "       [58.484444],\n",
              "       [76.51554 ],\n",
              "       [50.194664],\n",
              "       [78.443375],\n",
              "       [65.75048 ],\n",
              "       [67.1272  ],\n",
              "       [74.93399 ],\n",
              "       [73.8183  ],\n",
              "       [77.256004],\n",
              "       [56.08941 ],\n",
              "       [73.22244 ],\n",
              "       [71.95556 ],\n",
              "       [70.53724 ],\n",
              "       [72.159645],\n",
              "       [80.10672 ],\n",
              "       [74.168915],\n",
              "       [58.626312],\n",
              "       [73.492615],\n",
              "       [78.6616  ],\n",
              "       [55.83731 ],\n",
              "       [74.01274 ],\n",
              "       [67.50327 ],\n",
              "       [73.140625],\n",
              "       [62.67585 ],\n",
              "       [56.78499 ],\n",
              "       [69.16011 ],\n",
              "       [70.11144 ],\n",
              "       [68.233215],\n",
              "       [71.77432 ],\n",
              "       [79.134254],\n",
              "       [73.46404 ],\n",
              "       [65.57399 ],\n",
              "       [74.64467 ],\n",
              "       [63.649773],\n",
              "       [57.32525 ],\n",
              "       [58.51674 ],\n",
              "       [69.03828 ],\n",
              "       [76.636   ],\n",
              "       [57.57263 ],\n",
              "       [74.22466 ],\n",
              "       [70.959755],\n",
              "       [65.76811 ],\n",
              "       [71.769775],\n",
              "       [54.25361 ],\n",
              "       [75.67439 ],\n",
              "       [61.003807],\n",
              "       [61.034767],\n",
              "       [71.386154],\n",
              "       [79.78153 ],\n",
              "       [54.00991 ],\n",
              "       [53.19516 ],\n",
              "       [55.02671 ],\n",
              "       [60.757195],\n",
              "       [76.56907 ],\n",
              "       [54.64296 ],\n",
              "       [69.770485],\n",
              "       [76.30466 ],\n",
              "       [64.020744],\n",
              "       [68.261314],\n",
              "       [79.661125],\n",
              "       [55.818268],\n",
              "       [74.500565],\n",
              "       [68.334175],\n",
              "       [68.31942 ],\n",
              "       [76.714264],\n",
              "       [56.122627],\n",
              "       [73.027885],\n",
              "       [74.3896  ],\n",
              "       [72.733696],\n",
              "       [73.09439 ],\n",
              "       [60.601135],\n",
              "       [71.27692 ],\n",
              "       [69.83617 ],\n",
              "       [71.07799 ],\n",
              "       [66.18545 ],\n",
              "       [69.87958 ],\n",
              "       [54.63044 ],\n",
              "       [67.71509 ],\n",
              "       [78.65232 ],\n",
              "       [70.51773 ],\n",
              "       [72.3967  ],\n",
              "       [71.833176],\n",
              "       [62.13185 ],\n",
              "       [75.1503  ],\n",
              "       [69.29889 ],\n",
              "       [74.10175 ],\n",
              "       [53.55439 ],\n",
              "       [71.5798  ],\n",
              "       [75.39076 ],\n",
              "       [73.29808 ],\n",
              "       [75.561584],\n",
              "       [74.477066]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def predict_random_sample(model, X_test, y_test, scaler):\n",
        "    # Get a random sample index\n",
        "    random_index = random.randint(0, len(X_test) - 1)\n",
        "    \n",
        "    # Get the corresponding test sample and target value\n",
        "    test_sample = X_test[random_index]\n",
        "    true_life_expectancy = y_test.iloc[random_index]\n",
        "    \n",
        "    # Reshape the sample for prediction\n",
        "    test_sample_reshaped = test_sample.reshape(1, -1)\n",
        "    \n",
        "    # Make a prediction\n",
        "    predicted_life_expectancy = model.predict(test_sample_reshaped)[0][0]\n",
        "    \n",
        "    # Invert the scaling on the test sample\n",
        "    test_sample_original = scaler.inverse_transform(test_sample_reshaped)\n",
        "    \n",
        "    # Create a dataframe to display the original values\n",
        "    original_values = pd.DataFrame(test_sample_original, columns=X.columns)\n",
        "    \n",
        "    print(\"Original Parameters:\")\n",
        "    print(original_values)\n",
        "    print(f\"Actual Life Expectancy: {true_life_expectancy:.2f}\")\n",
        "    print(f\"Predicted Life Expectancy: {predicted_life_expectancy:.2f}\")\n",
        "\n",
        "# Call the function\n",
        "predict_random_sample(model, X_test, y_test, scaler)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA8SdfgSdyZB",
        "outputId": "f442d1d3-5d57-4ff6-dc2b-dca0b296efc8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "Original Parameters:\n",
            "   Country  Region    Year  Infant_deaths  Under_five_deaths  Adult_mortality  \\\n",
            "0     10.0     2.0  2015.0           12.0               14.0          158.589   \n",
            "\n",
            "   Alcohol_consumption  Hepatitis_B  Measles   BMI  Polio  Diphtheria  \\\n",
            "0                 9.27         95.0     83.0  27.9   95.0        95.0   \n",
            "\n",
            "   Incidents_HIV  GDP_per_capita  Population_mln  Thinness_ten_nineteen_years  \\\n",
            "0           0.34         31699.0            0.37                          2.5   \n",
            "\n",
            "   Thinness_five_nine_years  Schooling  Economy_status_Developed  \\\n",
            "0                       2.5       11.1                       0.0   \n",
            "\n",
            "   Economy_status_Developing  \n",
            "0                        1.0  \n",
            "Actual Life Expectancy: 73.10\n",
            "Predicted Life Expectancy: 71.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_random_sample(model, X_test, y_test, scaler, le_country, le_region):\n",
        "    # Get a random sample index\n",
        "    random_index = random.randint(0, len(X_test) - 1)\n",
        "    \n",
        "    # Get the corresponding test sample and target value\n",
        "    test_sample = X_test[random_index]\n",
        "    true_life_expectancy = y_test.iloc[random_index]\n",
        "    \n",
        "    # Reshape the sample for prediction\n",
        "    test_sample_reshaped = test_sample.reshape(1, -1)\n",
        "    \n",
        "    # Make a prediction\n",
        "    predicted_life_expectancy = model.predict(test_sample_reshaped)[0][0]\n",
        "    \n",
        "    # Invert the scaling on the test sample\n",
        "    test_sample_original = scaler.inverse_transform(test_sample_reshaped)\n",
        "    \n",
        "    # Create a dataframe to display the original values\n",
        "    original_values = pd.DataFrame(test_sample_original, columns=X.columns)\n",
        "    \n",
        "    # Get original Country and Region names\n",
        "    original_country = le_country.inverse_transform([int(original_values['Country'])])[0]\n",
        "    original_region = le_region.inverse_transform([int(original_values['Region'])])[0]\n",
        "    \n",
        "    original_values['Country'] = original_country\n",
        "    original_values['Region'] = original_region\n",
        "    \n",
        "    print(\"Original Parameters:\")\n",
        "    print(original_values)\n",
        "    print(f\"Actual Life Expectancy: {true_life_expectancy:.2f}\")\n",
        "    print(f\"Predicted Life Expectancy: {predicted_life_expectancy:.2f}\")\n",
        "\n",
        "# Call the function\n",
        "predict_random_sample(model, X_test, y_test, scaler, le_country=le_country, le_region=le_region)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJkkt7ChezQa",
        "outputId": "0970caf9-f4ec-4140-a7a2-e019df8bc112"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 110ms/step\n",
            "Original Parameters:\n",
            "  Country  Region    Year  Infant_deaths  Under_five_deaths  Adult_mortality  \\\n",
            "0  Angola  Africa  2004.0          105.7              175.1          329.306   \n",
            "\n",
            "   Alcohol_consumption  Hepatitis_B  Measles   BMI  Polio  Diphtheria  \\\n",
            "0                 2.41         67.0     64.0  22.2   18.0        40.0   \n",
            "\n",
            "   Incidents_HIV  GDP_per_capita  Population_mln  Thinness_ten_nineteen_years  \\\n",
            "0           1.45          2168.0           18.76                          1.2   \n",
            "\n",
            "   Thinness_five_nine_years  Schooling  Economy_status_Developed  \\\n",
            "0                       1.1        4.4                       0.0   \n",
            "\n",
            "   Economy_status_Developing  \n",
            "0                        1.0  \n",
            "Actual Life Expectancy: 49.30\n",
            "Predicted Life Expectancy: 53.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def predict_random_sample(model, X_test, y_test, scaler, le_country, le_region):\n",
        "    # Get a random sample index\n",
        "    random_index = random.randint(0, len(X_test) - 1)\n",
        "    \n",
        "    # Get the corresponding test sample and target value\n",
        "    test_sample = X_test[random_index]\n",
        "    true_life_expectancy = y_test.iloc[random_index]\n",
        "    \n",
        "    # Reshape the sample for prediction\n",
        "    test_sample_reshaped = test_sample.reshape(1, -1)\n",
        "    \n",
        "    # Make a prediction\n",
        "    predicted_life_expectancy = model.predict(test_sample_reshaped)[0][0]\n",
        "    \n",
        "    # Invert the scaling on the test sample\n",
        "    test_sample_original = scaler.inverse_transform(test_sample_reshaped)\n",
        "    \n",
        "    # Create a dataframe to display the original values\n",
        "    original_values = pd.DataFrame(test_sample_original, columns=X.columns)\n",
        "    \n",
        "    # Get original Country and Region names\n",
        "    original_country = le_country.inverse_transform([int(original_values['Country'])])[0]\n",
        "    original_region = le_region.inverse_transform([int(original_values['Region'])])[0]\n",
        "    \n",
        "    original_values['Country'] = original_country\n",
        "    original_values['Region'] = original_region\n",
        "    \n",
        "    print(\"Original Parameters:\")\n",
        "    display(original_values)\n",
        "    print(f\"Actual Life Expectancy: {true_life_expectancy:.2f}\")\n",
        "    print(f\"Predicted Life Expectancy: {predicted_life_expectancy:.2f}\")\n",
        "\n",
        "# Call the function\n",
        "predict_random_sample(model, X_test, y_test, scaler, le_country=le_country, le_region=le_region)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "EVj5v548gmkL",
        "outputId": "1919f0d5-d73b-486c-83dc-305b6ef49994"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "Original Parameters:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Country          Region    Year  Infant_deaths  Under_five_deaths  \\\n",
              "0  Latvia  European Union  2010.0            6.5                7.8   \n",
              "\n",
              "   Adult_mortality  Alcohol_consumption  Hepatitis_B  Measles   BMI  Polio  \\\n",
              "0         180.8715                 9.83         91.0     93.0  26.3   92.0   \n",
              "\n",
              "   Diphtheria  Incidents_HIV  GDP_per_capita  Population_mln  \\\n",
              "0        92.0           0.22         10964.0             2.1   \n",
              "\n",
              "   Thinness_ten_nineteen_years  Thinness_five_nine_years  Schooling  \\\n",
              "0                          2.2                       2.3       12.5   \n",
              "\n",
              "   Economy_status_Developed  Economy_status_Developing  \n",
              "0                       1.0                        0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bd903a3-f8a2-44a9-86b7-5614f78db731\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Region</th>\n",
              "      <th>Year</th>\n",
              "      <th>Infant_deaths</th>\n",
              "      <th>Under_five_deaths</th>\n",
              "      <th>Adult_mortality</th>\n",
              "      <th>Alcohol_consumption</th>\n",
              "      <th>Hepatitis_B</th>\n",
              "      <th>Measles</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Polio</th>\n",
              "      <th>Diphtheria</th>\n",
              "      <th>Incidents_HIV</th>\n",
              "      <th>GDP_per_capita</th>\n",
              "      <th>Population_mln</th>\n",
              "      <th>Thinness_ten_nineteen_years</th>\n",
              "      <th>Thinness_five_nine_years</th>\n",
              "      <th>Schooling</th>\n",
              "      <th>Economy_status_Developed</th>\n",
              "      <th>Economy_status_Developing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Latvia</td>\n",
              "      <td>European Union</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>7.8</td>\n",
              "      <td>180.8715</td>\n",
              "      <td>9.83</td>\n",
              "      <td>91.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>92.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>10964.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bd903a3-f8a2-44a9-86b7-5614f78db731')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1bd903a3-f8a2-44a9-86b7-5614f78db731 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1bd903a3-f8a2-44a9-86b7-5614f78db731');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Life Expectancy: 73.50\n",
            "Predicted Life Expectancy: 72.14\n"
          ]
        }
      ]
    }
  ]
}