{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kemk8wMOgEYo",
        "outputId": "46b4e3e2-641c-4773-c315-0aab736d7310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-04 09:11:00--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-04 09:11:00 (80.8 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get helper functions file\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper functions file\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poXymezziKop",
        "outputId": "dfb821e3-cf0a-4cc2-811b-334165727522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-04 09:11:05--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-04 09:11:05 (109 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "zEJhZtmGidUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data from Google Storage (already preformatted)\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip \n",
        "\n",
        "unzip_data(\"101_food_classes_10_percent.zip\")\n",
        "\n",
        "train_dir = \"101_food_classes_10_percent/train/\"\n",
        "test_dir = \"101_food_classes_10_percent/test/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXr7HJXeiCS-",
        "outputId": "e829e74a-f791-4eac-e3da-c4dcbf164687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-04 09:13:22--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.200.128, 74.125.68.128, 74.125.24.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.200.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1625420029 (1.5G) [application/zip]\n",
            "Saving to: ‘101_food_classes_10_percent.zip.1’\n",
            "\n",
            "101_food_classes_10 100%[===================>]   1.51G  22.1MB/s    in 69s     \n",
            "\n",
            "2023-04-04 09:14:32 (22.6 MB/s) - ‘101_food_classes_10_percent.zip.1’ saved [1625420029/1625420029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Step 2: Load the dataset\n",
        "data_dir = \"101_food_classes_10_percent\"\n",
        "train_dir = f\"{data_dir}/train\"\n",
        "test_dir = f\"{data_dir}/test\""
      ],
      "metadata": {
        "id": "4VOPJbkpkyRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NHNr1vomkzl1",
        "outputId": "c8793599-2a5c-421a-ddd2-15693e2d58cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'101_food_classes_10_percent/train'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "he8gEkN6k1RG",
        "outputId": "f40d992b-36ef-4993-df35-95e3f71270f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'101_food_classes_10_percent/test'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Preprocess the images\n",
        "image_size = (528, 528)  # EfficientNet-B6 input size\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=image_size,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=image_size,\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkyFHOp5k5Mq",
        "outputId": "4b621672-129c-435c-b7eb-e351f70140c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7575 images belonging to 101 classes.\n",
            "Found 25250 images belonging to 101 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create the model using pre-trained EfficientNet-B6 feature vector\n",
        "num_classes = 101\n",
        "\n",
        "feature_extractor_url = \"https://tfhub.dev/tensorflow/efficientnet/b6/feature-vector/1\"\n",
        "\n",
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
        "                                         input_shape=(528, 528, 3),\n",
        "                                         trainable=False)  # Freeze the feature extractor for initial training\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    feature_extractor_layer,\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_1koY-8ClBSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train the model with feature extraction\n",
        "initial_epochs = 10\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=test_generator)\n"
      ],
      "metadata": {
        "id": "IfPw7mlYlPmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Fine-tune the model\n",
        "# Unfreeze the feature extractor layer\n",
        "feature_extractor_layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "fine_tune_epochs = 10\n",
        "total_epochs = initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine_tune = model.fit(train_generator,\n",
        "                              epochs=total_epochs,\n",
        "                              initial_epoch=history.epoch[-1],\n",
        "                              validation_data=test_generator)\n"
      ],
      "metadata": {
        "id": "IU7sbfTgls2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_image(img_path, model):\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=image_size)\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = x / 255.0\n",
        "\n",
        "    # Make predictions\n",
        "    preds = model.predict(x)\n",
        "    predicted_class_index = np.argmax(preds[0])\n",
        "    confidence_score = np.max(preds[0])\n",
        "\n",
        "    # Get the class labels and predicted class label\n",
        "    class_labels = list(train_generator.class_indices.keys())\n",
        "    predicted_class = class_labels[predicted_class_index]\n",
        "\n",
        "    # Display the image, predicted class, and confidence score\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted: {predicted_class} ({confidence_score:.2f})\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return preds\n",
        "\n",
        "# Example: predict_image(\"path/to/image.jpg\", model)\n"
      ],
      "metadata": {
        "id": "69wXUbBHmGbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_image(\"path/to/image.jpg\", model)\n"
      ],
      "metadata": {
        "id": "ixki6sEfm2Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def predict_random_image(model, test_dir):\n",
        "    # Select a random food class directory from the test data\n",
        "    food_class_dirs = [d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))]\n",
        "    random_food_class = random.choice(food_class_dirs)\n",
        "    random_food_class_dir = os.path.join(test_dir, random_food_class)\n",
        "\n",
        "    # Select a random image from the chosen food class directory\n",
        "    image_files = [f for f in os.listdir(random_food_class_dir) if os.path.isfile(os.path.join(random_food_class_dir, f))]\n",
        "    random_image_file = random.choice(image_files)\n",
        "    random_image_path = os.path.join(random_food_class_dir, random_image_file)\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(random_image_path, target_size=image_size)\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = x / 255.0\n",
        "\n",
        "    # Make predictions\n",
        "    preds = model.predict(x)\n",
        "    predicted_class_index = np.argmax(preds[0])\n",
        "    confidence_score = np.max(preds[0])\n",
        "\n",
        "    # Get the class labels and predicted class label\n",
        "    class_labels = list(train_generator.class_indices.keys())\n",
        "    predicted_class = class_labels[predicted_class_index]\n",
        "\n",
        "    # Display the image, predicted class, and the actual class\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted: {predicted_class} ({confidence_score:.2f})\\nActual: {random_food_class}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return preds\n",
        "\n"
      ],
      "metadata": {
        "id": "vspYlj-bm6R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_random_image(model, test_dir)\n"
      ],
      "metadata": {
        "id": "6MaTSCMIm7mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create the model using pre-trained EfficientNet-B6 feature vector with GlobalAveragePooling2D\n",
        "num_classes = 101\n",
        "\n",
        "feature_extractor_url = \"https://tfhub.dev/tensorflow/efficientnet/b6/feature-vector/1\"\n",
        "\n",
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
        "                                         input_shape=(528, 528, 3),\n",
        "                                         trainable=False)  # Freeze the feature extractor for initial training\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    feature_extractor_layer,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model with feature extraction\n",
        "initial_epochs = 10\n",
        "\n",
        "checkpoint_filepath_feature_extraction = \"feature_extraction_checkpoint.h5\"\n",
        "model_checkpoint_callback_feature_extraction = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath_feature_extraction,\n",
        "    save_best_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    verbose=1)\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=test_generator,\n",
        "                    callbacks=[model_checkpoint_callback_feature_extraction])\n",
        "\n",
        "# Step 6: Fine-tune the model\n",
        "# Unfreeze the feature extractor layer\n",
        "feature_extractor_layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "fine_tune_epochs = 10\n",
        "total_epochs = initial_epochs + fine_tune_epochs\n",
        "\n",
        "checkpoint_filepath_fine_tuning = \"fine_tuning_checkpoint.h5\"\n",
        "model_checkpoint_callback_fine_tuning = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath_fine_tuning,\n",
        "    save_best_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    verbose=1)\n",
        "\n",
        "history_fine_tune = model.fit(train_generator,\n",
        "                              epochs=total_epochs,\n",
        "                              initial_epoch=history.epoch[-1],\n",
        "                              validation_data=test_generator,\n",
        "                              callbacks=[model_checkpoint_callback_fine_tuning])\n"
      ],
      "metadata": {
        "id": "urE3Pm3Wp995"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train the model with feature extraction\n",
        "initial_epochs = 10\n",
        "\n",
        "checkpoint_filepath_feature_extraction = \"feature_extraction_weights_checkpoint.h5\"\n",
        "model_checkpoint_callback_feature_extraction = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath_feature_extraction,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    verbose=1)\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=test_generator,\n",
        "                    callbacks=[model_checkpoint_callback_feature_extraction])\n",
        "\n",
        "# Load the best weights from the feature extraction phase before fine-tuning\n",
        "model.load_weights(checkpoint_filepath_feature_extraction)\n",
        "\n",
        "# Step 6: Fine-tune the model\n",
        "# Unfreeze the feature extractor layer\n",
        "feature_extractor_layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "fine_tune_epochs = 10\n",
        "total_epochs = initial_epochs + fine_tune_epochs\n",
        "\n",
        "checkpoint_filepath_fine_tuning = \"fine_tuning_checkpoint.h5\"\n",
        "model_checkpoint_callback_fine_tuning = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath_fine_tuning,\n",
        "    save_best_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    verbose=1)\n",
        "\n",
        "history_fine_tune = model.fit(train_generator,\n",
        "                              epochs=total_epochs,\n",
        "                              initial_epoch=history.epoch[-1],\n",
        "                              validation_data=test_generator,\n",
        "                              callbacks=[model_checkpoint_callback_fine_tuning])\n"
      ],
      "metadata": {
        "id": "jt3k59NYy9Lx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}